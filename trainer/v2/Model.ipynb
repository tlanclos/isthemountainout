{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2929 images belonging to 4 classes.\nFound 731 images belonging to 4 classes.\n"
    }
   ],
   "source": [
    "%run GpuOptions.ipynb\n",
    "%run BuildTrainingData.ipynb\n",
    "%run TrendTools.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 224, 224, 1)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 224, 224, 1)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 222, 222, 64) 640         lambda_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_transpose (Conv2DTranspo (None, 226, 226, 64) 640         lambda_3[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_4 (MaxPooling2D)  (None, 111, 111, 64) 0           conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_7 (MaxPooling2D)  (None, 113, 113, 64) 0           conv2d_transpose[0][0]           \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 109, 109, 64) 36928       max_pooling2d_4[0][0]            \n__________________________________________________________________________________________________\nconv2d_transpose_1 (Conv2DTrans (None, 115, 115, 64) 36928       max_pooling2d_7[0][0]            \n__________________________________________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D)  (None, 54, 54, 64)   0           conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_8 (MaxPooling2D)  (None, 57, 57, 64)   0           conv2d_transpose_1[0][0]         \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 52, 52, 64)   36928       max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\nconv2d_transpose_2 (Conv2DTrans (None, 59, 59, 64)   36928       max_pooling2d_8[0][0]            \n__________________________________________________________________________________________________\nmax_pooling2d_6 (MaxPooling2D)  (None, 26, 26, 64)   0           conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_9 (MaxPooling2D)  (None, 29, 29, 64)   0           conv2d_transpose_2[0][0]         \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 43264)        0           max_pooling2d_6[0][0]            \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 53824)        0           max_pooling2d_9[0][0]            \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 43264)        0           flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 53824)        0           flatten_3[0][0]                  \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 32)           1384480     dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 32)           1722400     dropout_4[0][0]                  \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 32)           0           dense_3[0][0]                    \n                                                                 dense_4[0][0]                    \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 32)           0           add_1[0][0]                      \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 4)            132         dropout_5[0][0]                  \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 4)            0           dense_5[0][0]                    \n==================================================================================================\nTotal params: 3,256,004\nTrainable params: 3,256,004\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import model as m\n",
    "\n",
    "classes = training_data_generator.class_indices\n",
    "data, _ = training_data_generator.next()\n",
    "shape = data[0].shape\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "outputs = m.chained(\n",
    "    tf.keras.layers.add([\n",
    "        m.chained(\n",
    "            inputs,\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda image: tf.image.rgb_to_grayscale(image)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32),\n",
    "        ),\n",
    "        m.chained(\n",
    "            inputs,\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda image: tf.image.rgb_to_grayscale(image)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32),\n",
    "        ),\n",
    "    ]),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(classes)),\n",
    "    tf.keras.layers.Activation('softmax'))\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.build(input_shape=(None, *shape))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.01),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, label_smoothing=0.05),\n",
    "    metrics=['accuracy'])\n",
    "if os.path.exists('isthemountainout.best.h5'):\n",
    "    model.load_weights('isthemountainout.best.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=========================] - 48s 527ms/step - loss: 0.8526 - accuracy: 0.9320 - val_loss: 0.9016 - val_accuracy: 0.8793\nEpoch 631/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8551 - accuracy: 0.9312\nEpoch 00631: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 759ms/step - loss: 0.8548 - accuracy: 0.9313 - val_loss: 0.9087 - val_accuracy: 0.8622\nEpoch 632/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8543 - accuracy: 0.9271\nEpoch 00632: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 515ms/step - loss: 0.8544 - accuracy: 0.9268 - val_loss: 0.8971 - val_accuracy: 0.8736\nEpoch 633/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8569 - accuracy: 0.9236\nEpoch 00633: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 756ms/step - loss: 0.8569 - accuracy: 0.9237 - val_loss: 0.8996 - val_accuracy: 0.8778\nEpoch 634/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8540 - accuracy: 0.9277\nEpoch 00634: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 515ms/step - loss: 0.8536 - accuracy: 0.9285 - val_loss: 0.8975 - val_accuracy: 0.8821\nEpoch 635/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8568 - accuracy: 0.9271\nEpoch 00635: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 759ms/step - loss: 0.8562 - accuracy: 0.9279 - val_loss: 0.9005 - val_accuracy: 0.8736\nEpoch 636/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8554 - accuracy: 0.9284\nEpoch 00636: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 517ms/step - loss: 0.8554 - accuracy: 0.9285 - val_loss: 0.9008 - val_accuracy: 0.8736\nEpoch 637/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8529 - accuracy: 0.9302\nEpoch 00637: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8530 - accuracy: 0.9299 - val_loss: 0.9043 - val_accuracy: 0.8665\nEpoch 638/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8547 - accuracy: 0.9274\nEpoch 00638: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 50s 546ms/step - loss: 0.8544 - accuracy: 0.9279 - val_loss: 0.9006 - val_accuracy: 0.8693\nEpoch 639/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8523 - accuracy: 0.9326\nEpoch 00639: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 70s 769ms/step - loss: 0.8525 - accuracy: 0.9323 - val_loss: 0.8958 - val_accuracy: 0.8807\nEpoch 640/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8550 - accuracy: 0.9298\nEpoch 00640: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 515ms/step - loss: 0.8543 - accuracy: 0.9306 - val_loss: 0.8972 - val_accuracy: 0.8835\nEpoch 641/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8536 - accuracy: 0.9309\nEpoch 00641: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 759ms/step - loss: 0.8537 - accuracy: 0.9306 - val_loss: 0.8975 - val_accuracy: 0.8778\nEpoch 642/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8555 - accuracy: 0.9260\nEpoch 00642: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8557 - accuracy: 0.9258 - val_loss: 0.9074 - val_accuracy: 0.8693\nEpoch 643/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8505 - accuracy: 0.9347\nEpoch 00643: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 755ms/step - loss: 0.8512 - accuracy: 0.9341 - val_loss: 0.8952 - val_accuracy: 0.8835\nEpoch 644/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8530 - accuracy: 0.9309\nEpoch 00644: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 512ms/step - loss: 0.8528 - accuracy: 0.9310 - val_loss: 0.8979 - val_accuracy: 0.8736\nEpoch 645/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8557 - accuracy: 0.9246\nEpoch 00645: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 756ms/step - loss: 0.8550 - accuracy: 0.9251 - val_loss: 0.9043 - val_accuracy: 0.8665\nEpoch 646/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8522 - accuracy: 0.9347\nEpoch 00646: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8517 - accuracy: 0.9355 - val_loss: 0.9024 - val_accuracy: 0.8764\nEpoch 647/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8526 - accuracy: 0.9316\nEpoch 00647: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 72s 789ms/step - loss: 0.8524 - accuracy: 0.9317 - val_loss: 0.9004 - val_accuracy: 0.8764\nEpoch 648/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8532 - accuracy: 0.9274\nEpoch 00648: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 48s 525ms/step - loss: 0.8531 - accuracy: 0.9275 - val_loss: 0.8959 - val_accuracy: 0.8778\nEpoch 649/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8534 - accuracy: 0.9305\nEpoch 00649: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 756ms/step - loss: 0.8534 - accuracy: 0.9306 - val_loss: 0.8963 - val_accuracy: 0.8764\nEpoch 650/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8524 - accuracy: 0.9302\nEpoch 00650: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 514ms/step - loss: 0.8524 - accuracy: 0.9299 - val_loss: 0.8985 - val_accuracy: 0.8736\nEpoch 651/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8545 - accuracy: 0.9291\nEpoch 00651: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 755ms/step - loss: 0.8545 - accuracy: 0.9289 - val_loss: 0.9003 - val_accuracy: 0.8764\nEpoch 652/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8532 - accuracy: 0.9312\nEpoch 00652: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8528 - accuracy: 0.9320 - val_loss: 0.8968 - val_accuracy: 0.8764\nEpoch 653/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8523 - accuracy: 0.9337\nEpoch 00653: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 754ms/step - loss: 0.8531 - accuracy: 0.9327 - val_loss: 0.8990 - val_accuracy: 0.8750\nEpoch 654/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8530 - accuracy: 0.9291\nEpoch 00654: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8528 - accuracy: 0.9296 - val_loss: 0.8991 - val_accuracy: 0.8807\nEpoch 655/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8511 - accuracy: 0.9319\nEpoch 00655: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8508 - accuracy: 0.9323 - val_loss: 0.8989 - val_accuracy: 0.8778\nEpoch 656/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8548 - accuracy: 0.9291\nEpoch 00656: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 50s 545ms/step - loss: 0.8546 - accuracy: 0.9296 - val_loss: 0.8968 - val_accuracy: 0.8793\nEpoch 657/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8521 - accuracy: 0.9316\nEpoch 00657: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 70s 771ms/step - loss: 0.8519 - accuracy: 0.9320 - val_loss: 0.9034 - val_accuracy: 0.8679\nEpoch 658/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8531 - accuracy: 0.9312\nEpoch 00658: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8526 - accuracy: 0.9317 - val_loss: 0.9007 - val_accuracy: 0.8778\nEpoch 659/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8537 - accuracy: 0.9281\nEpoch 00659: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8544 - accuracy: 0.9272 - val_loss: 0.9000 - val_accuracy: 0.8764\nEpoch 660/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8537 - accuracy: 0.9295\nEpoch 00660: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 515ms/step - loss: 0.8530 - accuracy: 0.9303 - val_loss: 0.8960 - val_accuracy: 0.8821\nEpoch 661/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8488 - accuracy: 0.9344\nEpoch 00661: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 761ms/step - loss: 0.8489 - accuracy: 0.9344 - val_loss: 0.8997 - val_accuracy: 0.8722\nEpoch 662/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8527 - accuracy: 0.9281\nEpoch 00662: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 514ms/step - loss: 0.8524 - accuracy: 0.9285 - val_loss: 0.9083 - val_accuracy: 0.8636\nEpoch 663/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8526 - accuracy: 0.9309\nEpoch 00663: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8519 - accuracy: 0.9317 - val_loss: 0.9011 - val_accuracy: 0.8722\nEpoch 664/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8543 - accuracy: 0.9288\nEpoch 00664: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8544 - accuracy: 0.9285 - val_loss: 0.8941 - val_accuracy: 0.8835\nEpoch 665/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8575 - accuracy: 0.9222\nEpoch 00665: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 72s 789ms/step - loss: 0.8571 - accuracy: 0.9223 - val_loss: 0.8953 - val_accuracy: 0.8793\nEpoch 666/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8509 - accuracy: 0.9337\nEpoch 00666: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 50s 544ms/step - loss: 0.8509 - accuracy: 0.9334 - val_loss: 0.8949 - val_accuracy: 0.8764\nEpoch 667/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8505 - accuracy: 0.9330\nEpoch 00667: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 758ms/step - loss: 0.8502 - accuracy: 0.9334 - val_loss: 0.8931 - val_accuracy: 0.8821\nEpoch 668/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8510 - accuracy: 0.9326\nEpoch 00668: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8513 - accuracy: 0.9323 - val_loss: 0.9005 - val_accuracy: 0.8750\nEpoch 669/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8514 - accuracy: 0.9319\nEpoch 00669: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 755ms/step - loss: 0.8513 - accuracy: 0.9323 - val_loss: 0.8951 - val_accuracy: 0.8778\nEpoch 670/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8502 - accuracy: 0.9323\nEpoch 00670: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 515ms/step - loss: 0.8500 - accuracy: 0.9323 - val_loss: 0.8961 - val_accuracy: 0.8807\nEpoch 671/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8499 - accuracy: 0.9340\nEpoch 00671: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 758ms/step - loss: 0.8501 - accuracy: 0.9337 - val_loss: 0.8949 - val_accuracy: 0.8807\nEpoch 672/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8517 - accuracy: 0.9316\nEpoch 00672: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 516ms/step - loss: 0.8514 - accuracy: 0.9320 - val_loss: 0.8992 - val_accuracy: 0.8778\nEpoch 673/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8540 - accuracy: 0.9281\nEpoch 00673: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8539 - accuracy: 0.9282 - val_loss: 0.8986 - val_accuracy: 0.8764\nEpoch 674/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8519 - accuracy: 0.9302\nEpoch 00674: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 50s 549ms/step - loss: 0.8517 - accuracy: 0.9303 - val_loss: 0.8972 - val_accuracy: 0.8736\nEpoch 675/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8504 - accuracy: 0.9326\nEpoch 00675: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 70s 772ms/step - loss: 0.8498 - accuracy: 0.9334 - val_loss: 0.8981 - val_accuracy: 0.8807\nEpoch 676/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8502 - accuracy: 0.9326\nEpoch 00676: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 514ms/step - loss: 0.8506 - accuracy: 0.9323 - val_loss: 0.8943 - val_accuracy: 0.8849\nEpoch 677/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8508 - accuracy: 0.9312\nEpoch 00677: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 754ms/step - loss: 0.8504 - accuracy: 0.9317 - val_loss: 0.8921 - val_accuracy: 0.8835\nEpoch 678/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8504 - accuracy: 0.9323\nEpoch 00678: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 513ms/step - loss: 0.8503 - accuracy: 0.9320 - val_loss: 0.8962 - val_accuracy: 0.8778\nEpoch 679/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8493 - accuracy: 0.9344\nEpoch 00679: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 756ms/step - loss: 0.8494 - accuracy: 0.9344 - val_loss: 0.8988 - val_accuracy: 0.8764\nEpoch 680/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8518 - accuracy: 0.9316\nEpoch 00680: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 512ms/step - loss: 0.8514 - accuracy: 0.9320 - val_loss: 0.8939 - val_accuracy: 0.8807\nEpoch 681/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8496 - accuracy: 0.9333\nEpoch 00681: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 756ms/step - loss: 0.8501 - accuracy: 0.9327 - val_loss: 0.8971 - val_accuracy: 0.8778\nEpoch 682/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8473 - accuracy: 0.9386\nEpoch 00682: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 514ms/step - loss: 0.8475 - accuracy: 0.9386 - val_loss: 0.8963 - val_accuracy: 0.8778\nEpoch 683/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8511 - accuracy: 0.9305\nEpoch 00683: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 72s 792ms/step - loss: 0.8507 - accuracy: 0.9310 - val_loss: 0.8954 - val_accuracy: 0.8835\nEpoch 684/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8492 - accuracy: 0.9337\nEpoch 00684: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 48s 530ms/step - loss: 0.8493 - accuracy: 0.9334 - val_loss: 0.8899 - val_accuracy: 0.8864\nEpoch 685/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8513 - accuracy: 0.9316\nEpoch 00685: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8511 - accuracy: 0.9317 - val_loss: 0.8966 - val_accuracy: 0.8764\nEpoch 686/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8496 - accuracy: 0.9309\nEpoch 00686: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 514ms/step - loss: 0.8491 - accuracy: 0.9313 - val_loss: 0.8945 - val_accuracy: 0.8835\nEpoch 687/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8476 - accuracy: 0.9333\nEpoch 00687: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8483 - accuracy: 0.9327 - val_loss: 0.8929 - val_accuracy: 0.8849\nEpoch 688/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8498 - accuracy: 0.9344\nEpoch 00688: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 514ms/step - loss: 0.8496 - accuracy: 0.9344 - val_loss: 0.8986 - val_accuracy: 0.8750\nEpoch 689/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8479 - accuracy: 0.9340\nEpoch 00689: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 758ms/step - loss: 0.8476 - accuracy: 0.9341 - val_loss: 0.8976 - val_accuracy: 0.8807\nEpoch 690/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8513 - accuracy: 0.9291\nEpoch 00690: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 512ms/step - loss: 0.8513 - accuracy: 0.9289 - val_loss: 0.8970 - val_accuracy: 0.8764\nEpoch 691/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8493 - accuracy: 0.9330\nEpoch 00691: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 758ms/step - loss: 0.8491 - accuracy: 0.9330 - val_loss: 0.8931 - val_accuracy: 0.8835\nEpoch 692/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8494 - accuracy: 0.9326\nEpoch 00692: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 50s 548ms/step - loss: 0.8490 - accuracy: 0.9330 - val_loss: 0.8964 - val_accuracy: 0.8821\nEpoch 693/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8514 - accuracy: 0.9288\nEpoch 00693: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 70s 772ms/step - loss: 0.8513 - accuracy: 0.9289 - val_loss: 0.8910 - val_accuracy: 0.8835\nEpoch 694/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8470 - accuracy: 0.9365\nEpoch 00694: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 515ms/step - loss: 0.8474 - accuracy: 0.9361 - val_loss: 0.8944 - val_accuracy: 0.8821\nEpoch 695/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8471 - accuracy: 0.9344\nEpoch 00695: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 757ms/step - loss: 0.8470 - accuracy: 0.9344 - val_loss: 0.8979 - val_accuracy: 0.8736\nEpoch 696/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8485 - accuracy: 0.9358\nEpoch 00696: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 517ms/step - loss: 0.8481 - accuracy: 0.9361 - val_loss: 0.8935 - val_accuracy: 0.8807\nEpoch 697/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8482 - accuracy: 0.9351\nEpoch 00697: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 756ms/step - loss: 0.8480 - accuracy: 0.9355 - val_loss: 0.8925 - val_accuracy: 0.8864\nEpoch 698/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8467 - accuracy: 0.9372\nEpoch 00698: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 516ms/step - loss: 0.8464 - accuracy: 0.9375 - val_loss: 0.8958 - val_accuracy: 0.8750\nEpoch 699/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8442 - accuracy: 0.9389\nEpoch 00699: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 69s 760ms/step - loss: 0.8445 - accuracy: 0.9386 - val_loss: 0.8943 - val_accuracy: 0.8835\nEpoch 700/700\n90/91 [============================>.] - ETA: 0s - loss: 0.8485 - accuracy: 0.9351\nEpoch 00700: val_accuracy did not improve from 0.88636\n91/91 [==============================] - 47s 515ms/step - loss: 0.8483 - accuracy: 0.9355 - val_loss: 0.8957 - val_accuracy: 0.8821\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2c0c8a3ab88>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "!rm -rf logs\n",
    "time.sleep(2)\n",
    "\n",
    "model.fit(\n",
    "    training_data_generator,\n",
    "    epochs=700,\n",
    "    verbose=True,\n",
    "    steps_per_epoch=training_data_generator.samples // \n",
    "        training_data_generator.batch_size,\n",
    "    validation_data=validation_data_generator,\n",
    "    validation_steps=validation_data_generator.samples // \n",
    "        validation_data_generator.batch_size,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'isthemountainout.best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=50,\n",
    "            restore_best_weights=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.CSVLogger(os.path.join('logs', 'isthemountainout.training.csv')),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='logs', update_freq='batch', write_images=True, write_graph=True, embeddings_freq=10),\n",
    "        m.LogConfusionMatrixCallback(\n",
    "            model=model,\n",
    "            datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\\\n",
    "                .flow_from_directory(data_directory, batch_size=3096, shuffle=True, target_size=image_size),\n",
    "            logdir=os.path.join('logs', 'image'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf_gpu': conda)",
   "language": "python",
   "name": "python_defaultSpec_1600739726693"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}