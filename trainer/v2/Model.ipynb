{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2929 images belonging to 4 classes.\nFound 731 images belonging to 4 classes.\n"
    }
   ],
   "source": [
    "%run GpuOptions.ipynb\n",
    "%run BuildTrainingData.ipynb\n",
    "%run TrendTools.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: &quot;functional_5&quot;\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nlambda_4 (Lambda)               (None, 224, 224, 1)  0           input_3[0][0]                    \n__________________________________________________________________________________________________\nlambda_5 (Lambda)               (None, 224, 224, 1)  0           input_3[0][0]                    \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 222, 222, 64) 640         lambda_4[0][0]                   \n__________________________________________________________________________________________________\nconv2d_transpose_6 (Conv2DTrans (None, 226, 226, 64) 640         lambda_5[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_12 (MaxPooling2D) (None, 111, 111, 64) 0           conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_15 (MaxPooling2D) (None, 113, 113, 64) 0           conv2d_transpose_6[0][0]         \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 109, 109, 64) 36928       max_pooling2d_12[0][0]           \n__________________________________________________________________________________________________\nconv2d_transpose_7 (Conv2DTrans (None, 115, 115, 64) 36928       max_pooling2d_15[0][0]           \n__________________________________________________________________________________________________\nmax_pooling2d_13 (MaxPooling2D) (None, 54, 54, 64)   0           conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_16 (MaxPooling2D) (None, 57, 57, 64)   0           conv2d_transpose_7[0][0]         \n__________________________________________________________________________________________________\ndropout_14 (Dropout)            (None, 54, 54, 64)   0           max_pooling2d_13[0][0]           \n__________________________________________________________________________________________________\ndropout_16 (Dropout)            (None, 57, 57, 64)   0           max_pooling2d_16[0][0]           \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 52, 52, 64)   36928       dropout_14[0][0]                 \n__________________________________________________________________________________________________\nconv2d_transpose_8 (Conv2DTrans (None, 59, 59, 64)   36928       dropout_16[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_14 (MaxPooling2D) (None, 26, 26, 64)   0           conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_17 (MaxPooling2D) (None, 29, 29, 64)   0           conv2d_transpose_8[0][0]         \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 43264)        0           max_pooling2d_14[0][0]           \n__________________________________________________________________________________________________\nflatten_5 (Flatten)             (None, 53824)        0           max_pooling2d_17[0][0]           \n__________________________________________________________________________________________________\ndropout_15 (Dropout)            (None, 43264)        0           flatten_4[0][0]                  \n__________________________________________________________________________________________________\ndropout_17 (Dropout)            (None, 53824)        0           flatten_5[0][0]                  \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 32)           1384480     dropout_15[0][0]                 \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 32)           1722400     dropout_17[0][0]                 \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 32)           0           dense_6[0][0]                    \n                                                                 dense_7[0][0]                    \n__________________________________________________________________________________________________\ndropout_18 (Dropout)            (None, 32)           0           add_2[0][0]                      \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 4)            132         dropout_18[0][0]                 \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 4)            0           dense_8[0][0]                    \n==================================================================================================\nTotal params: 3,256,004\nTrainable params: 3,256,004\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import common.model as m\n",
    "\n",
    "classes = training_data_generator.class_indices\n",
    "data, _ = training_data_generator.next()\n",
    "shape = data[0].shape\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "outputs = m.chained(\n",
    "    tf.keras.layers.add([\n",
    "        m.chained(\n",
    "            inputs,\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda image: tf.image.rgb_to_grayscale(image)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32),\n",
    "        ),\n",
    "        m.chained(\n",
    "            inputs,\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda image: tf.image.rgb_to_grayscale(image)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32),\n",
    "        ),\n",
    "    ]),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(classes)),\n",
    "    tf.keras.layers.Activation('softmax'))\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.build(input_shape=(None, *shape))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.01),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, label_smoothing=0.1),\n",
    "    metrics=['accuracy'])\n",
    "if os.path.exists('isthemountainout.h5'):\n",
    "    model.load_weights('isthemountainout.h5')\n",
    "elif os.path.exists('isthemountainout.best.h5'):\n",
    "    model.load_weights('isthemountainout.best.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 3660 images belonging to 4 classes.\nEpoch 1/700\n 2/91 [..............................] - ETA: 1:07 - loss: 1.0217 - accuracy: 0.7551WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1050s vs `on_train_batch_end` time: 1.4157s). Check your callbacks.\n91/91 [==============================] - ETA: 0s - loss: 0.9229 - accuracy: 0.8447\nEpoch 00001: val_accuracy improved from -inf to 0.78409, saving model to isthemountainout.best.h5\n91/91 [==============================] - 51s 560ms/step - loss: 0.9229 - accuracy: 0.8447 - val_loss: 0.9846 - val_accuracy: 0.7841\nEpoch 2/700\n91/91 [==============================] - ETA: 0s - loss: 0.8896 - accuracy: 0.8840\nEpoch 00002: val_accuracy did not improve from 0.78409\n91/91 [==============================] - 43s 468ms/step - loss: 0.8896 - accuracy: 0.8840 - val_loss: 1.0284 - val_accuracy: 0.7401\nEpoch 3/700\n91/91 [==============================] - ETA: 0s - loss: 0.8869 - accuracy: 0.8878\nEpoch 00003: val_accuracy did not improve from 0.78409\n91/91 [==============================] - 49s 535ms/step - loss: 0.8869 - accuracy: 0.8878 - val_loss: 1.0004 - val_accuracy: 0.7628\nEpoch 4/700\n91/91 [==============================] - ETA: 0s - loss: 0.8836 - accuracy: 0.8926\nEpoch 00004: val_accuracy did not improve from 0.78409\n91/91 [==============================] - 43s 468ms/step - loss: 0.8836 - accuracy: 0.8926 - val_loss: 1.0256 - val_accuracy: 0.7457\nEpoch 5/700\n91/91 [==============================] - ETA: 0s - loss: 0.8875 - accuracy: 0.8861\nEpoch 00005: val_accuracy improved from 0.78409 to 0.78835, saving model to isthemountainout.best.h5\n91/91 [==============================] - 49s 539ms/step - loss: 0.8875 - accuracy: 0.8861 - val_loss: 0.9840 - val_accuracy: 0.7884\nEpoch 6/700\n91/91 [==============================] - ETA: 0s - loss: 0.8887 - accuracy: 0.8826\nEpoch 00006: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 473ms/step - loss: 0.8887 - accuracy: 0.8826 - val_loss: 0.9946 - val_accuracy: 0.7713\nEpoch 7/700\n91/91 [==============================] - ETA: 0s - loss: 0.8843 - accuracy: 0.8902\nEpoch 00007: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 539ms/step - loss: 0.8843 - accuracy: 0.8902 - val_loss: 1.0057 - val_accuracy: 0.7685\nEpoch 8/700\n91/91 [==============================] - ETA: 0s - loss: 0.8832 - accuracy: 0.8956\nEpoch 00008: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 471ms/step - loss: 0.8832 - accuracy: 0.8956 - val_loss: 0.9889 - val_accuracy: 0.7855\nEpoch 9/700\n91/91 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.8902\nEpoch 00009: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 538ms/step - loss: 0.8853 - accuracy: 0.8902 - val_loss: 1.0049 - val_accuracy: 0.7685\nEpoch 10/700\n91/91 [==============================] - ETA: 0s - loss: 0.8835 - accuracy: 0.8937\nEpoch 00010: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 468ms/step - loss: 0.8835 - accuracy: 0.8937 - val_loss: 0.9887 - val_accuracy: 0.7869\nEpoch 11/700\n91/91 [==============================] - ETA: 0s - loss: 0.8813 - accuracy: 0.8926\nEpoch 00011: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 540ms/step - loss: 0.8813 - accuracy: 0.8926 - val_loss: 0.9925 - val_accuracy: 0.7841\nEpoch 12/700\n91/91 [==============================] - ETA: 0s - loss: 0.8789 - accuracy: 0.8985\nEpoch 00012: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 44s 480ms/step - loss: 0.8789 - accuracy: 0.8985 - val_loss: 1.0045 - val_accuracy: 0.7741\nEpoch 13/700\n91/91 [==============================] - ETA: 0s - loss: 0.8786 - accuracy: 0.8982\nEpoch 00013: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 542ms/step - loss: 0.8786 - accuracy: 0.8982 - val_loss: 1.0115 - val_accuracy: 0.7614\nEpoch 14/700\n91/91 [==============================] - ETA: 0s - loss: 0.8776 - accuracy: 0.8989\nEpoch 00014: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 476ms/step - loss: 0.8776 - accuracy: 0.8989 - val_loss: 1.0190 - val_accuracy: 0.7528\nEpoch 15/700\n91/91 [==============================] - ETA: 0s - loss: 0.8788 - accuracy: 0.8989\nEpoch 00015: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 50s 547ms/step - loss: 0.8788 - accuracy: 0.8989 - val_loss: 1.0609 - val_accuracy: 0.6903\nEpoch 16/700\n91/91 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.8989\nEpoch 00016: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 475ms/step - loss: 0.8807 - accuracy: 0.8989 - val_loss: 1.0248 - val_accuracy: 0.7429\nEpoch 17/700\n91/91 [==============================] - ETA: 0s - loss: 0.8881 - accuracy: 0.8889\nEpoch 00017: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 537ms/step - loss: 0.8881 - accuracy: 0.8889 - val_loss: 1.0063 - val_accuracy: 0.7656\nEpoch 18/700\n91/91 [==============================] - ETA: 0s - loss: 0.8796 - accuracy: 0.8992\nEpoch 00018: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 472ms/step - loss: 0.8796 - accuracy: 0.8992 - val_loss: 0.9940 - val_accuracy: 0.7770\nEpoch 19/700\n91/91 [==============================] - ETA: 0s - loss: 0.8800 - accuracy: 0.8961\nEpoch 00019: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 538ms/step - loss: 0.8800 - accuracy: 0.8961 - val_loss: 1.0091 - val_accuracy: 0.7628\nEpoch 20/700\n91/91 [==============================] - ETA: 0s - loss: 0.8790 - accuracy: 0.8958\nEpoch 00020: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 471ms/step - loss: 0.8790 - accuracy: 0.8958 - val_loss: 1.0127 - val_accuracy: 0.7557\nEpoch 21/700\n91/91 [==============================] - ETA: 0s - loss: 0.8789 - accuracy: 0.8992\nEpoch 00021: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 540ms/step - loss: 0.8789 - accuracy: 0.8992 - val_loss: 1.0332 - val_accuracy: 0.7244\nEpoch 22/700\n91/91 [==============================] - ETA: 0s - loss: 0.8773 - accuracy: 0.9016\nEpoch 00022: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 476ms/step - loss: 0.8773 - accuracy: 0.9016 - val_loss: 1.0104 - val_accuracy: 0.7642\nEpoch 23/700\n91/91 [==============================] - ETA: 0s - loss: 0.8729 - accuracy: 0.9023\nEpoch 00023: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 535ms/step - loss: 0.8729 - accuracy: 0.9023 - val_loss: 1.0352 - val_accuracy: 0.7315\nEpoch 24/700\n91/91 [==============================] - ETA: 0s - loss: 0.8789 - accuracy: 0.8964\nEpoch 00024: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 469ms/step - loss: 0.8789 - accuracy: 0.8964 - val_loss: 1.0177 - val_accuracy: 0.7528\nEpoch 25/700\n91/91 [==============================] - ETA: 0s - loss: 0.8782 - accuracy: 0.8978\nEpoch 00025: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 536ms/step - loss: 0.8782 - accuracy: 0.8978 - val_loss: 1.0392 - val_accuracy: 0.7230\nEpoch 26/700\n91/91 [==============================] - ETA: 0s - loss: 0.8759 - accuracy: 0.9011\nEpoch 00026: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 472ms/step - loss: 0.8759 - accuracy: 0.9011 - val_loss: 1.0072 - val_accuracy: 0.7656\nEpoch 27/700\n91/91 [==============================] - ETA: 0s - loss: 0.8782 - accuracy: 0.9016\nEpoch 00027: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 534ms/step - loss: 0.8782 - accuracy: 0.9016 - val_loss: 1.0602 - val_accuracy: 0.6903\nEpoch 28/700\n91/91 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.9020\nEpoch 00028: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 471ms/step - loss: 0.8753 - accuracy: 0.9020 - val_loss: 1.0464 - val_accuracy: 0.7131\nEpoch 29/700\n91/91 [==============================] - ETA: 0s - loss: 0.8750 - accuracy: 0.9013\nEpoch 00029: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 50s 545ms/step - loss: 0.8750 - accuracy: 0.9013 - val_loss: 1.0607 - val_accuracy: 0.6889\nEpoch 30/700\n91/91 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.9037\nEpoch 00030: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 44s 480ms/step - loss: 0.8753 - accuracy: 0.9037 - val_loss: 1.0421 - val_accuracy: 0.7173\nEpoch 31/700\n91/91 [==============================] - ETA: 0s - loss: 0.8775 - accuracy: 0.9006\nEpoch 00031: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 50s 547ms/step - loss: 0.8775 - accuracy: 0.9006 - val_loss: 1.0600 - val_accuracy: 0.6946\nEpoch 32/700\n91/91 [==============================] - ETA: 0s - loss: 0.8777 - accuracy: 0.8992\nEpoch 00032: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 475ms/step - loss: 0.8777 - accuracy: 0.8992 - val_loss: 1.0226 - val_accuracy: 0.7528\nEpoch 33/700\n91/91 [==============================] - ETA: 0s - loss: 0.8804 - accuracy: 0.8932\nEpoch 00033: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 543ms/step - loss: 0.8804 - accuracy: 0.8932 - val_loss: 1.0326 - val_accuracy: 0.7486\nEpoch 34/700\n91/91 [==============================] - ETA: 0s - loss: 0.8733 - accuracy: 0.9047\nEpoch 00034: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 476ms/step - loss: 0.8733 - accuracy: 0.9047 - val_loss: 1.0447 - val_accuracy: 0.7216\nEpoch 35/700\n91/91 [==============================] - ETA: 0s - loss: 0.8735 - accuracy: 0.9033\nEpoch 00035: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 543ms/step - loss: 0.8735 - accuracy: 0.9033 - val_loss: 1.0495 - val_accuracy: 0.7074\nEpoch 36/700\n91/91 [==============================] - ETA: 0s - loss: 0.8781 - accuracy: 0.9002\nEpoch 00036: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 471ms/step - loss: 0.8781 - accuracy: 0.9002 - val_loss: 1.0503 - val_accuracy: 0.7031\nEpoch 37/700\n91/91 [==============================] - ETA: 0s - loss: 0.8748 - accuracy: 0.9020\nEpoch 00037: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 534ms/step - loss: 0.8748 - accuracy: 0.9020 - val_loss: 1.0773 - val_accuracy: 0.6577\nEpoch 38/700\n91/91 [==============================] - ETA: 0s - loss: 0.8739 - accuracy: 0.9051\nEpoch 00038: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 469ms/step - loss: 0.8739 - accuracy: 0.9051 - val_loss: 1.0561 - val_accuracy: 0.6946\nEpoch 39/700\n91/91 [==============================] - ETA: 0s - loss: 0.8771 - accuracy: 0.9009\nEpoch 00039: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 539ms/step - loss: 0.8771 - accuracy: 0.9009 - val_loss: 1.0432 - val_accuracy: 0.7244\nEpoch 40/700\n91/91 [==============================] - ETA: 0s - loss: 0.8802 - accuracy: 0.8964\nEpoch 00040: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 471ms/step - loss: 0.8802 - accuracy: 0.8964 - val_loss: 1.0864 - val_accuracy: 0.6392\nEpoch 41/700\n91/91 [==============================] - ETA: 0s - loss: 0.8767 - accuracy: 0.9002\nEpoch 00041: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 538ms/step - loss: 0.8767 - accuracy: 0.9002 - val_loss: 1.0694 - val_accuracy: 0.6719\nEpoch 42/700\n91/91 [==============================] - ETA: 0s - loss: 0.8797 - accuracy: 0.8996\nEpoch 00042: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 469ms/step - loss: 0.8797 - accuracy: 0.8996 - val_loss: 1.0676 - val_accuracy: 0.6761\nEpoch 43/700\n91/91 [==============================] - ETA: 0s - loss: 0.8755 - accuracy: 0.9033\nEpoch 00043: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 535ms/step - loss: 0.8755 - accuracy: 0.9033 - val_loss: 1.0605 - val_accuracy: 0.6974\nEpoch 44/700\n91/91 [==============================] - ETA: 0s - loss: 0.8723 - accuracy: 0.9051\nEpoch 00044: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 473ms/step - loss: 0.8723 - accuracy: 0.9051 - val_loss: 1.0568 - val_accuracy: 0.6946\nEpoch 45/700\n91/91 [==============================] - ETA: 0s - loss: 0.8714 - accuracy: 0.9073\nEpoch 00045: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 538ms/step - loss: 0.8714 - accuracy: 0.9073 - val_loss: 1.0873 - val_accuracy: 0.6520\nEpoch 46/700\n91/91 [==============================] - ETA: 0s - loss: 0.8698 - accuracy: 0.9078\nEpoch 00046: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 469ms/step - loss: 0.8698 - accuracy: 0.9078 - val_loss: 1.0954 - val_accuracy: 0.6449\nEpoch 47/700\n91/91 [==============================] - ETA: 0s - loss: 0.8713 - accuracy: 0.9068\nEpoch 00047: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 537ms/step - loss: 0.8713 - accuracy: 0.9068 - val_loss: 1.0666 - val_accuracy: 0.6761\nEpoch 48/700\n91/91 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.9065\nEpoch 00048: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 469ms/step - loss: 0.8707 - accuracy: 0.9065 - val_loss: 1.0375 - val_accuracy: 0.7244\nEpoch 49/700\n91/91 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.9027\nEpoch 00049: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 49s 536ms/step - loss: 0.8749 - accuracy: 0.9027 - val_loss: 1.0860 - val_accuracy: 0.6491\nEpoch 50/700\n91/91 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.9058\nEpoch 00050: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 474ms/step - loss: 0.8705 - accuracy: 0.9058 - val_loss: 1.0448 - val_accuracy: 0.7230\nEpoch 51/700\n91/91 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.9082\nEpoch 00051: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 50s 550ms/step - loss: 0.8699 - accuracy: 0.9082 - val_loss: 1.0916 - val_accuracy: 0.6364\nEpoch 52/700\n91/91 [==============================] - ETA: 0s - loss: 0.8683 - accuracy: 0.9113\nEpoch 00052: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 43s 474ms/step - loss: 0.8683 - accuracy: 0.9113 - val_loss: 1.0728 - val_accuracy: 0.6619\nEpoch 53/700\n91/91 [==============================] - ETA: 0s - loss: 0.8717 - accuracy: 0.9075\nEpoch 00053: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 50s 552ms/step - loss: 0.8717 - accuracy: 0.9075 - val_loss: 1.0600 - val_accuracy: 0.6918\nEpoch 54/700\n91/91 [==============================] - ETA: 0s - loss: 0.8735 - accuracy: 0.9040\nEpoch 00054: val_accuracy did not improve from 0.78835\n91/91 [==============================] - 44s 479ms/step - loss: 0.8735 - accuracy: 0.9040 - val_loss: 1.0642 - val_accuracy: 0.6875\nEpoch 55/700\n91/91 [==============================] - ETA: 0s - loss: 0.8716 - accuracy: 0.9068\nEpoch 00055: val_accuracy did not improve from 0.78835\nRestoring model weights from the end of the best epoch.\n91/91 [==============================] - 50s 551ms/step - loss: 0.8716 - accuracy: 0.9068 - val_loss: 1.1154 - val_accuracy: 0.6136\nEpoch 00055: early stopping\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;tensorflow.python.keras.callbacks.History at 0x1f08b132400&gt;"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import time\n",
    "!rm -rf logs\n",
    "time.sleep(2)\n",
    "\n",
    "model.fit(\n",
    "    training_data_generator,\n",
    "    epochs=700,\n",
    "    verbose=True,\n",
    "    steps_per_epoch=training_data_generator.samples // \n",
    "        training_data_generator.batch_size,\n",
    "    validation_data=validation_data_generator,\n",
    "    validation_steps=validation_data_generator.samples // \n",
    "        validation_data_generator.batch_size,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'isthemountainout.best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=50,\n",
    "            restore_best_weights=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.CSVLogger(os.path.join('logs', 'isthemountainout.training.csv')),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='logs', update_freq='batch', write_images=True, write_graph=True, embeddings_freq=10),\n",
    "        m.LogConfusionMatrixCallback(\n",
    "            model=model,\n",
    "            datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\\\n",
    "                .flow_from_directory(data_directory, batch_size=3096, shuffle=True, target_size=image_size),\n",
    "            logdir=os.path.join('logs', 'image'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1601602695169",
   "display_name": "Python 3.8.5 64-bit ('tf_gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}