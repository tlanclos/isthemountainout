{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6085 images belonging to 4 classes.\n",
      "Found 1520 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "%run GpuOptions.ipynb\n",
    "%run BuildTrainingData.ipynb\n",
    "%run TrendTools.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 112, 112, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 112, 112, 32) 128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 112, 112, 32) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 112, 112, 64) 18496       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 112, 112, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 112, 112, 64) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 112, 112, 64) 0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_36 (SeparableC (None, 112, 112, 128 8896        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 112, 112, 128 512         separable_conv2d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 112, 112, 128 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_37 (SeparableC (None, 112, 112, 128 17664       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 112, 112, 128 512         separable_conv2d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 128)  8320        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 56, 56, 128)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 56, 56, 128)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_38 (SeparableC (None, 56, 56, 256)  34176       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 56, 56, 256)  1024        separable_conv2d_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 56, 56, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_39 (SeparableC (None, 56, 56, 256)  68096       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 56, 56, 256)  1024        separable_conv2d_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 28, 28, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 256)  33024       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 28, 28, 256)  0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 28, 28, 256)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_40 (SeparableC (None, 28, 28, 728)  189400      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 28, 28, 728)  2912        separable_conv2d_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 28, 28, 728)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_41 (SeparableC (None, 28, 28, 728)  537264      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 28, 28, 728)  2912        separable_conv2d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 728)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 728)  187096      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 14, 14, 728)  0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 14, 14, 728)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_42 (SeparableC (None, 14, 14, 728)  537264      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 14, 14, 728)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_43 (SeparableC (None, 14, 14, 728)  537264      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 14, 14, 728)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_44 (SeparableC (None, 14, 14, 728)  537264      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 14, 14, 728)  0           batch_normalization_48[0][0]     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 14, 14, 728)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_45 (SeparableC (None, 14, 14, 728)  537264      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 14, 14, 728)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_46 (SeparableC (None, 14, 14, 728)  537264      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 14, 14, 728)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_47 (SeparableC (None, 14, 14, 728)  537264      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 14, 14, 728)  0           batch_normalization_51[0][0]     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 14, 14, 728)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_48 (SeparableC (None, 14, 14, 728)  537264      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 14, 14, 728)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_49 (SeparableC (None, 14, 14, 728)  537264      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 14, 14, 728)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_50 (SeparableC (None, 14, 14, 728)  537264      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 14, 14, 728)  0           batch_normalization_54[0][0]     \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 14, 14, 728)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_51 (SeparableC (None, 14, 14, 728)  537264      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 14, 14, 728)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_52 (SeparableC (None, 14, 14, 728)  537264      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 14, 14, 728)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_53 (SeparableC (None, 14, 14, 728)  537264      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 14, 14, 728)  0           batch_normalization_57[0][0]     \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 14, 14, 728)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_54 (SeparableC (None, 14, 14, 728)  537264      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 14, 14, 728)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_55 (SeparableC (None, 14, 14, 728)  537264      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 14, 14, 728)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_56 (SeparableC (None, 14, 14, 728)  537264      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 728)  0           batch_normalization_60[0][0]     \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 14, 14, 728)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_57 (SeparableC (None, 14, 14, 728)  537264      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 14, 14, 728)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_58 (SeparableC (None, 14, 14, 728)  537264      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 14, 14, 728)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_59 (SeparableC (None, 14, 14, 728)  537264      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 14, 14, 728)  0           batch_normalization_63[0][0]     \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 14, 14, 728)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_60 (SeparableC (None, 14, 14, 728)  537264      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 14, 14, 728)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_61 (SeparableC (None, 14, 14, 728)  537264      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 14, 14, 728)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_62 (SeparableC (None, 14, 14, 728)  537264      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 14, 14, 728)  0           batch_normalization_66[0][0]     \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 14, 14, 728)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_63 (SeparableC (None, 14, 14, 728)  537264      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 14, 14, 728)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_64 (SeparableC (None, 14, 14, 728)  537264      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 14, 14, 728)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_65 (SeparableC (None, 14, 14, 728)  537264      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 14, 14, 728)  0           batch_normalization_69[0][0]     \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 14, 14, 728)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_66 (SeparableC (None, 14, 14, 728)  537264      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 14, 14, 728)  2912        separable_conv2d_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 14, 14, 728)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_67 (SeparableC (None, 14, 14, 1024) 753048      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 14, 14, 1024) 4096        separable_conv2d_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 1024)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 1024)   746496      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 7, 7, 1024)   0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 1024)   0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_34 (SeparableC (None, 7, 7, 728)    755416      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 728)    2912        separable_conv2d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 728)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_35 (SeparableC (None, 7, 7, 1024)   753048      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 1024)   4096        separable_conv2d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            4100        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,640,220\n",
      "Trainable params: 17,593,628\n",
      "Non-trainable params: 46,592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import common.model as m\n",
    "\n",
    "classes = training_data_generator.class_indices\n",
    "data, _ = training_data_generator.next()\n",
    "shape = data[0].shape\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "\n",
    "outputs = m.chained(\n",
    "    # Entry Flow\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    m.expand(\n",
    "        flow=lambda previous_activation, size: tf.keras.layers.add([\n",
    "            m.chained(\n",
    "                m.duplicate(\n",
    "                    layers=lambda: [\n",
    "                        tf.keras.layers.Activation('relu'),\n",
    "                        tf.keras.layers.SeparableConv2D(filters=size, kernel_size=3, padding='same'),\n",
    "                        tf.keras.layers.BatchNormalization(),\n",
    "                    ],\n",
    "                    count=2\n",
    "                ),\n",
    "                tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same'),\n",
    "            )(previous_activation),\n",
    "            tf.keras.layers.Conv2D(filters=size, kernel_size=1, strides=2, padding='same')(previous_activation),\n",
    "        ]),\n",
    "        values=[128, 256, 728],\n",
    "    ),\n",
    "\n",
    "    # # Middle Flow\n",
    "    m.expand(\n",
    "        flow=lambda previous_activation, _: tf.keras.layers.add([\n",
    "            m.duplicate(\n",
    "                layers=lambda: [\n",
    "                    tf.keras.layers.Activation('relu'),\n",
    "                    tf.keras.layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                ],\n",
    "                count=3,\n",
    "            )(previous_activation),\n",
    "            previous_activation,\n",
    "        ]),\n",
    "        values=[0] * 8\n",
    "    ),\n",
    "\n",
    "    # # Exit Flow\n",
    "    lambda previous_activation: tf.keras.layers.add([\n",
    "        m.chained(\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.SeparableConv2D(filters=1024, kernel_size=3, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same'),\n",
    "        )(previous_activation),\n",
    "        tf.keras.layers.Conv2D(filters=1024, kernel_size=1, strides=2, padding='same')(previous_activation),\n",
    "    ]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.SeparableConv2D(filters=1024, kernel_size=3, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(classes), activation='linear'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    ")(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.build(input_shape=(None, *shape))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.008),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, label_smoothing=0.1),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "if os.path.exists('isthemountainout.best.h5'):\n",
    "    model.load_weights('isthemountainout.best.h5')\n",
    "elif os.path.exists('isthemountainout.h5'):\n",
    "    model.load_weights('isthemountainout.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7605 images belonging to 4 classes.\n",
      "Epoch 1/700\n",
      "   2/1521 [..............................] - ETA: 1:53:09 - loss: 0.5435 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0505s vs `on_train_batch_end` time: 8.8881s). Check your callbacks.\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.6525 - accuracy: 0.8382\n",
      "Epoch 00001: val_loss improved from inf to 0.54704, saving model to isthemountainout.best.h5\n",
      "1521/1521 [==============================] - 216s 142ms/step - loss: 0.6525 - accuracy: 0.8382 - val_loss: 0.5470 - val_accuracy: 0.9039\n",
      "Epoch 2/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.8551\n",
      "Epoch 00002: val_loss improved from 0.54704 to 0.53147, saving model to isthemountainout.best.h5\n",
      "1521/1521 [==============================] - 201s 132ms/step - loss: 0.6233 - accuracy: 0.8551 - val_loss: 0.5315 - val_accuracy: 0.9125\n",
      "Epoch 3/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.8564\n",
      "Epoch 00003: val_loss improved from 0.53147 to 0.52893, saving model to isthemountainout.best.h5\n",
      "1521/1521 [==============================] - 187s 123ms/step - loss: 0.6094 - accuracy: 0.8564 - val_loss: 0.5289 - val_accuracy: 0.9105\n",
      "Epoch 4/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.8701\n",
      "Epoch 00004: val_loss did not improve from 0.52893\n",
      "1521/1521 [==============================] - 189s 125ms/step - loss: 0.5971 - accuracy: 0.8701 - val_loss: 0.5490 - val_accuracy: 0.9059\n",
      "Epoch 5/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.8686\n",
      "Epoch 00005: val_loss did not improve from 0.52893\n",
      "1521/1521 [==============================] - 192s 126ms/step - loss: 0.5946 - accuracy: 0.8686 - val_loss: 0.5601 - val_accuracy: 0.9033\n",
      "Epoch 6/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5826 - accuracy: 0.8765\n",
      "Epoch 00006: val_loss improved from 0.52893 to 0.52833, saving model to isthemountainout.best.h5\n",
      "1521/1521 [==============================] - 183s 121ms/step - loss: 0.5826 - accuracy: 0.8765 - val_loss: 0.5283 - val_accuracy: 0.9178\n",
      "Epoch 7/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.8750\n",
      "Epoch 00007: val_loss did not improve from 0.52833\n",
      "1521/1521 [==============================] - 195s 128ms/step - loss: 0.5842 - accuracy: 0.8750 - val_loss: 0.5405 - val_accuracy: 0.9151\n",
      "Epoch 8/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.8808\n",
      "Epoch 00008: val_loss did not improve from 0.52833\n",
      "1521/1521 [==============================] - 180s 119ms/step - loss: 0.5726 - accuracy: 0.8808 - val_loss: 0.5343 - val_accuracy: 0.9145\n",
      "Epoch 9/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.8836\n",
      "Epoch 00009: val_loss did not improve from 0.52833\n",
      "1521/1521 [==============================] - 165s 108ms/step - loss: 0.5708 - accuracy: 0.8836 - val_loss: 0.5442 - val_accuracy: 0.9039\n",
      "Epoch 10/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.8823\n",
      "Epoch 00010: val_loss did not improve from 0.52833\n",
      "1521/1521 [==============================] - 173s 114ms/step - loss: 0.5672 - accuracy: 0.8823 - val_loss: 0.5712 - val_accuracy: 0.9039\n",
      "Epoch 11/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.8847\n",
      "Epoch 00011: val_loss did not improve from 0.52833\n",
      "1521/1521 [==============================] - 174s 114ms/step - loss: 0.5611 - accuracy: 0.8847 - val_loss: 0.5652 - val_accuracy: 0.8980\n",
      "Epoch 12/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.8768\n",
      "Epoch 00012: val_loss improved from 0.52833 to 0.52717, saving model to isthemountainout.best.h5\n",
      "1521/1521 [==============================] - 164s 108ms/step - loss: 0.5674 - accuracy: 0.8768 - val_loss: 0.5272 - val_accuracy: 0.9197\n",
      "Epoch 13/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.8870\n",
      "Epoch 00013: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 174s 114ms/step - loss: 0.5605 - accuracy: 0.8870 - val_loss: 0.5655 - val_accuracy: 0.8987\n",
      "Epoch 14/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8952\n",
      "Epoch 00014: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 173s 113ms/step - loss: 0.5448 - accuracy: 0.8952 - val_loss: 0.5833 - val_accuracy: 0.8987\n",
      "Epoch 15/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.8852\n",
      "Epoch 00015: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 162s 106ms/step - loss: 0.5563 - accuracy: 0.8852 - val_loss: 0.5435 - val_accuracy: 0.9145\n",
      "Epoch 16/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.8898\n",
      "Epoch 00016: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5544 - accuracy: 0.8898 - val_loss: 0.5493 - val_accuracy: 0.9053\n",
      "Epoch 17/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.8870\n",
      "Epoch 00017: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5569 - accuracy: 0.8870 - val_loss: 0.5654 - val_accuracy: 0.9059\n",
      "Epoch 18/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.8926\n",
      "Epoch 00018: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 161s 106ms/step - loss: 0.5517 - accuracy: 0.8926 - val_loss: 0.5364 - val_accuracy: 0.9230\n",
      "Epoch 19/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.8943\n",
      "Epoch 00019: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5530 - accuracy: 0.8943 - val_loss: 0.5407 - val_accuracy: 0.9132\n",
      "Epoch 20/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.8929\n",
      "Epoch 00020: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5501 - accuracy: 0.8929 - val_loss: 0.5376 - val_accuracy: 0.9138\n",
      "Epoch 21/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.8972\n",
      "Epoch 00021: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 161s 106ms/step - loss: 0.5452 - accuracy: 0.8972 - val_loss: 0.5603 - val_accuracy: 0.9151\n",
      "Epoch 22/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8913\n",
      "Epoch 00022: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5473 - accuracy: 0.8913 - val_loss: 0.5288 - val_accuracy: 0.9184\n",
      "Epoch 23/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.8905\n",
      "Epoch 00023: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 110ms/step - loss: 0.5474 - accuracy: 0.8905 - val_loss: 0.5563 - val_accuracy: 0.9079\n",
      "Epoch 24/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.8952\n",
      "Epoch 00024: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 161s 106ms/step - loss: 0.5408 - accuracy: 0.8952 - val_loss: 0.5356 - val_accuracy: 0.9191\n",
      "Epoch 25/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.8905\n",
      "Epoch 00025: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 170s 111ms/step - loss: 0.5471 - accuracy: 0.8905 - val_loss: 0.5563 - val_accuracy: 0.9105\n",
      "Epoch 26/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5416 - accuracy: 0.9000\n",
      "Epoch 00026: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5416 - accuracy: 0.9000 - val_loss: 0.5822 - val_accuracy: 0.8947\n",
      "Epoch 27/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.8966\n",
      "Epoch 00027: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 161s 106ms/step - loss: 0.5427 - accuracy: 0.8966 - val_loss: 0.5589 - val_accuracy: 0.9046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5324 - accuracy: 0.9043\n",
      "Epoch 00028: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 110ms/step - loss: 0.5324 - accuracy: 0.9043 - val_loss: 0.5602 - val_accuracy: 0.9033\n",
      "Epoch 29/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.8878\n",
      "Epoch 00029: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5539 - accuracy: 0.8878 - val_loss: 0.5734 - val_accuracy: 0.9026\n",
      "Epoch 30/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.8992\n",
      "Epoch 00030: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5413 - accuracy: 0.8992 - val_loss: 0.5792 - val_accuracy: 0.9053\n",
      "Epoch 31/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.9046\n",
      "Epoch 00031: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5298 - accuracy: 0.9046 - val_loss: 0.5769 - val_accuracy: 0.9013\n",
      "Epoch 32/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.8961\n",
      "Epoch 00032: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5396 - accuracy: 0.8961 - val_loss: 0.5557 - val_accuracy: 0.9086\n",
      "Epoch 33/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.8880\n",
      "Epoch 00033: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5509 - accuracy: 0.8880 - val_loss: 0.5899 - val_accuracy: 0.9007\n",
      "Epoch 34/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.8994\n",
      "Epoch 00034: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5304 - accuracy: 0.8994 - val_loss: 0.5746 - val_accuracy: 0.9086\n",
      "Epoch 35/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.8995\n",
      "Epoch 00035: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5333 - accuracy: 0.8995 - val_loss: 0.5789 - val_accuracy: 0.9099\n",
      "Epoch 36/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8951\n",
      "Epoch 00036: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5381 - accuracy: 0.8951 - val_loss: 0.5417 - val_accuracy: 0.9178\n",
      "Epoch 37/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.8923\n",
      "Epoch 00037: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5422 - accuracy: 0.8923 - val_loss: 0.5639 - val_accuracy: 0.9086\n",
      "Epoch 38/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.9005\n",
      "Epoch 00038: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5370 - accuracy: 0.9005 - val_loss: 0.5835 - val_accuracy: 0.8987\n",
      "Epoch 39/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.8997\n",
      "Epoch 00039: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5337 - accuracy: 0.8997 - val_loss: 0.5591 - val_accuracy: 0.9066\n",
      "Epoch 40/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.9092\n",
      "Epoch 00040: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5244 - accuracy: 0.9092 - val_loss: 0.5614 - val_accuracy: 0.9039\n",
      "Epoch 41/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.9003\n",
      "Epoch 00041: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5351 - accuracy: 0.9003 - val_loss: 0.5586 - val_accuracy: 0.9151\n",
      "Epoch 42/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5360 - accuracy: 0.9018\n",
      "Epoch 00042: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5360 - accuracy: 0.9018 - val_loss: 0.5649 - val_accuracy: 0.9086\n",
      "Epoch 43/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.9089\n",
      "Epoch 00043: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 110ms/step - loss: 0.5193 - accuracy: 0.9089 - val_loss: 0.5611 - val_accuracy: 0.9125\n",
      "Epoch 44/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.8999\n",
      "Epoch 00044: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 110ms/step - loss: 0.5295 - accuracy: 0.8999 - val_loss: 0.5469 - val_accuracy: 0.9145\n",
      "Epoch 45/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.9043\n",
      "Epoch 00045: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5230 - accuracy: 0.9043 - val_loss: 0.5565 - val_accuracy: 0.9059\n",
      "Epoch 46/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.9033\n",
      "Epoch 00046: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5303 - accuracy: 0.9033 - val_loss: 0.5649 - val_accuracy: 0.9059\n",
      "Epoch 47/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.9023\n",
      "Epoch 00047: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5258 - accuracy: 0.9023 - val_loss: 0.5920 - val_accuracy: 0.9039\n",
      "Epoch 48/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.9074\n",
      "Epoch 00048: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 161s 106ms/step - loss: 0.5210 - accuracy: 0.9074 - val_loss: 0.5933 - val_accuracy: 0.9039\n",
      "Epoch 49/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5307 - accuracy: 0.8992\n",
      "Epoch 00049: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5307 - accuracy: 0.8992 - val_loss: 0.5701 - val_accuracy: 0.9066\n",
      "Epoch 50/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.9007\n",
      "Epoch 00050: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5290 - accuracy: 0.9007 - val_loss: 0.5890 - val_accuracy: 0.8941\n",
      "Epoch 51/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.8997\n",
      "Epoch 00051: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5338 - accuracy: 0.8997 - val_loss: 0.5796 - val_accuracy: 0.9112\n",
      "Epoch 52/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.9066\n",
      "Epoch 00052: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5230 - accuracy: 0.9066 - val_loss: 0.5617 - val_accuracy: 0.9118\n",
      "Epoch 53/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 0.8951\n",
      "Epoch 00053: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5352 - accuracy: 0.8951 - val_loss: 0.5719 - val_accuracy: 0.9046\n",
      "Epoch 54/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.9068\n",
      "Epoch 00054: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 161s 106ms/step - loss: 0.5213 - accuracy: 0.9068 - val_loss: 0.5554 - val_accuracy: 0.9086\n",
      "Epoch 55/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.9054\n",
      "Epoch 00055: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5257 - accuracy: 0.9054 - val_loss: 0.5348 - val_accuracy: 0.9164\n",
      "Epoch 56/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.9061\n",
      "Epoch 00056: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5206 - accuracy: 0.9061 - val_loss: 0.5598 - val_accuracy: 0.9145\n",
      "Epoch 57/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.9064\n",
      "Epoch 00057: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5246 - accuracy: 0.9064 - val_loss: 0.5603 - val_accuracy: 0.9112\n",
      "Epoch 58/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.8951\n",
      "Epoch 00058: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5302 - accuracy: 0.8951 - val_loss: 0.5519 - val_accuracy: 0.9112\n",
      "Epoch 59/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.9081\n",
      "Epoch 00059: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5222 - accuracy: 0.9081 - val_loss: 0.5548 - val_accuracy: 0.9072\n",
      "Epoch 60/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.9023\n",
      "Epoch 00060: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 160s 105ms/step - loss: 0.5253 - accuracy: 0.9023 - val_loss: 0.5391 - val_accuracy: 0.9164\n",
      "Epoch 61/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.8999\n",
      "Epoch 00061: val_loss did not improve from 0.52717\n",
      "1521/1521 [==============================] - 169s 111ms/step - loss: 0.5290 - accuracy: 0.8999 - val_loss: 0.5655 - val_accuracy: 0.9105\n",
      "Epoch 62/700\n",
      "1521/1521 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.9003\n",
      "Epoch 00062: val_loss did not improve from 0.52717\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1521/1521 [==============================] - 168s 111ms/step - loss: 0.5284 - accuracy: 0.9003 - val_loss: 0.5501 - val_accuracy: 0.9158\n",
      "Epoch 00062: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebe18a5400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model.fit(\n",
    "    training_data_generator,\n",
    "    epochs=700,\n",
    "    verbose=True,\n",
    "    steps_per_epoch=training_data_generator.samples // \n",
    "        training_data_generator.batch_size,\n",
    "    validation_data=validation_data_generator,\n",
    "    validation_steps=validation_data_generator.samples // \n",
    "        validation_data_generator.batch_size,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'isthemountainout.best.h5',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=50,\n",
    "            restore_best_weights=True,\n",
    "            verbose=True),\n",
    "        # tf.keras.callbacks.CSVLogger(os.path.join('logs', 'isthemountainout.training.csv')),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join('logs', 'fit', datetime.now().strftime('%Y%m%d%H%M%S')),\n",
    "            update_freq=50,\n",
    "            write_images=True,\n",
    "            write_graph=True,\n",
    "            embeddings_freq=10),\n",
    "        m.LogConfusionMatrixCallback(\n",
    "            model=model,\n",
    "            datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\\\n",
    "                .flow_from_directory(data_directory, batch_size=3096, shuffle=True, target_size=image_size),\n",
    "            logdir=os.path.join('logs', 'image'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
