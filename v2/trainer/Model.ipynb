{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling memory growth on PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "%run setup/GpuOptions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3106 files belonging to 4 classes.\n",
      "Using 2485 files for training.\n",
      "Found 3106 files belonging to 4 classes.\n",
      "Using 621 files for validation.\n",
      "loading weights from best\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1920, 1080,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " random_translation_2 (RandomTr  (None, 1920, 1080,   0          ['input_3[0][0]']                \n",
      " anslation)                     3)                                                                \n",
      "                                                                                                  \n",
      " random_brightness_2 (RandomBri  (None, 1920, 1080,   0          ['random_translation_2[0][0]']   \n",
      " ghtness)                       3)                                                                \n",
      "                                                                                                  \n",
      " cropping2d_2 (Cropping2D)      (None, 1410, 50, 3)  0           ['random_brightness_2[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 705, 25, 32)  896         ['cropping2d_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 705, 25, 32)  128        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 705, 25, 32)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 705, 25, 64)  18496       ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 705, 25, 64)  256        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 705, 25, 64)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 705, 25, 64)  0           ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " separable_conv2d_70 (Separable  (None, 705, 25, 128  8896       ['activation_76[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 705, 25, 128  512        ['separable_conv2d_70[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 705, 25, 128  0           ['batch_normalization_76[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_71 (Separable  (None, 705, 25, 128  17664      ['activation_77[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 705, 25, 128  512        ['separable_conv2d_71[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 353, 13, 128  0          ['batch_normalization_77[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 353, 13, 128  8320        ['activation_73[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 353, 13, 128  0           ['max_pooling2d_8[0][0]',        \n",
      "                                )                                 'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 353, 13, 128  0           ['add_24[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_72 (Separable  (None, 353, 13, 256  34176      ['activation_78[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 353, 13, 256  1024       ['separable_conv2d_72[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 353, 13, 256  0           ['batch_normalization_78[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_73 (Separable  (None, 353, 13, 256  68096      ['activation_79[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 353, 13, 256  1024       ['separable_conv2d_73[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 177, 7, 256)  0          ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 177, 7, 256)  33024       ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 177, 7, 256)  0           ['max_pooling2d_9[0][0]',        \n",
      "                                                                  'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 177, 7, 256)  0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_74 (Separable  (None, 177, 7, 728)  189400     ['activation_80[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 177, 7, 728)  2912       ['separable_conv2d_74[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 177, 7, 728)  0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_75 (Separable  (None, 177, 7, 728)  537264     ['activation_81[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 177, 7, 728)  2912       ['separable_conv2d_75[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 89, 4, 728)  0           ['batch_normalization_81[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 89, 4, 728)   187096      ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 89, 4, 728)   0           ['max_pooling2d_10[0][0]',       \n",
      "                                                                  'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 89, 4, 728)   0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_76 (Separable  (None, 89, 4, 728)  537264      ['activation_82[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_76[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_77 (Separable  (None, 89, 4, 728)  537264      ['activation_83[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_77[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_78 (Separable  (None, 89, 4, 728)  537264      ['activation_84[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_78[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_84[0][0]', \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 89, 4, 728)   0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_79 (Separable  (None, 89, 4, 728)  537264      ['activation_85[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_79[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_80 (Separable  (None, 89, 4, 728)  537264      ['activation_86[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_80[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_81 (Separable  (None, 89, 4, 728)  537264      ['activation_87[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_81[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_87[0][0]', \n",
      "                                                                  'add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 89, 4, 728)   0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_82 (Separable  (None, 89, 4, 728)  537264      ['activation_88[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_82[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_83 (Separable  (None, 89, 4, 728)  537264      ['activation_89[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_83[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_84 (Separable  (None, 89, 4, 728)  537264      ['activation_90[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_84[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_90[0][0]', \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 89, 4, 728)   0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_85 (Separable  (None, 89, 4, 728)  537264      ['activation_91[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_85[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_86 (Separable  (None, 89, 4, 728)  537264      ['activation_92[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_86[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_87 (Separable  (None, 89, 4, 728)  537264      ['activation_93[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_87[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_93[0][0]', \n",
      "                                                                  'add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 89, 4, 728)   0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_88 (Separable  (None, 89, 4, 728)  537264      ['activation_94[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_88[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_89 (Separable  (None, 89, 4, 728)  537264      ['activation_95[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_89[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_90 (Separable  (None, 89, 4, 728)  537264      ['activation_96[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_90[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_96[0][0]', \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 89, 4, 728)   0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_91 (Separable  (None, 89, 4, 728)  537264      ['activation_97[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_91[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_92 (Separable  (None, 89, 4, 728)  537264      ['activation_98[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_92[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_93 (Separable  (None, 89, 4, 728)  537264      ['activation_99[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_93[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_99[0][0]', \n",
      "                                                                  'add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 89, 4, 728)   0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_94 (Separable  (None, 89, 4, 728)  537264      ['activation_100[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_94[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_95 (Separable  (None, 89, 4, 728)  537264      ['activation_101[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_95[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_96 (Separable  (None, 89, 4, 728)  537264      ['activation_102[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_96[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_102[0][0]',\n",
      "                                                                  'add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 89, 4, 728)   0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_97 (Separable  (None, 89, 4, 728)  537264      ['activation_103[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_97[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_98 (Separable  (None, 89, 4, 728)  537264      ['activation_104[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_98[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_99 (Separable  (None, 89, 4, 728)  537264      ['activation_105[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_99[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_105[0][0]',\n",
      "                                                                  'add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 89, 4, 728)   0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_100 (Separabl  (None, 89, 4, 728)  537264      ['activation_106[0][0]']         \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_100[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_101 (Separabl  (None, 89, 4, 1024)  753048     ['activation_107[0][0]']         \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 89, 4, 1024)  4096       ['separable_conv2d_101[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 45, 2, 1024)  0          ['batch_normalization_107[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 45, 2, 1024)  746496      ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 45, 2, 1024)  0           ['max_pooling2d_11[0][0]',       \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 45, 2, 1024)  0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_68 (Separable  (None, 45, 2, 728)  755416      ['activation_74[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 45, 2, 728)  2912        ['separable_conv2d_68[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 45, 2, 728)   0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_69 (Separable  (None, 45, 2, 1024)  753048     ['activation_75[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 45, 2, 1024)  4096       ['separable_conv2d_69[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 1024)        0           ['batch_normalization_75[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4)            4100        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,640,220\n",
      "Trainable params: 17,593,628\n",
      "Non-trainable params: 46,592\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, optimizers, losses\n",
    "import common.model as m\n",
    "from common.dataset import Dataset\n",
    "\n",
    "dataset = Dataset(\n",
    "    '../dataset/dataset-2022-10-19T22-51-08',\n",
    "    batch_size=8,\n",
    "    image_size=(1920, 1080))\n",
    "augmentation = [\n",
    "    layers.RandomTranslation(0.05, 0.05, fill_mode='nearest'),\n",
    "    layers.RandomBrightness(0.025),\n",
    "    # Cropping2D parameter are how much to take off of top, bottom, \n",
    "    # left and right, not a rectangle of the cropped image\n",
    "    layers.Cropping2D(cropping=((160, 350), (580, 450))),\n",
    "]\n",
    "classes = dataset.training.class_names\n",
    "data, _ = next(iter(dataset.training))\n",
    "shape = data[0].shape\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "\n",
    "outputs = m.chained(\n",
    "    # Augmentations\n",
    "    *augmentation,\n",
    "    # Entry Flow\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    m.expand(\n",
    "        flow=lambda previous_activation, size: layers.add([\n",
    "            m.chained(\n",
    "                m.duplicate(\n",
    "                    layers=lambda: [\n",
    "                        layers.Activation('relu'),\n",
    "                        layers.SeparableConv2D(filters=size, kernel_size=3, padding='same'),\n",
    "                        layers.BatchNormalization(),\n",
    "                    ],\n",
    "                    count=2\n",
    "                ),\n",
    "                layers.MaxPooling2D(pool_size=3, strides=2, padding='same'),\n",
    "            )(previous_activation),\n",
    "            layers.Conv2D(filters=size, kernel_size=1, strides=2, padding='same')(previous_activation),\n",
    "        ]),\n",
    "        values=[128, 256, 728],\n",
    "    ),\n",
    "\n",
    "    # Middle Flow\n",
    "    m.expand(\n",
    "        flow=lambda previous_activation, _: layers.add([\n",
    "            m.duplicate(\n",
    "                layers=lambda: [\n",
    "                    layers.Activation('relu'),\n",
    "                    layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "                    layers.BatchNormalization(),\n",
    "                ],\n",
    "                count=3,\n",
    "            )(previous_activation),\n",
    "            previous_activation,\n",
    "        ]),\n",
    "        values=[0] * 8\n",
    "    ),\n",
    "\n",
    "    # Exit Flow\n",
    "    lambda previous_activation: layers.add([\n",
    "        m.chained(\n",
    "            layers.Activation('relu'),\n",
    "            layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.SeparableConv2D(filters=1024, kernel_size=3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(pool_size=3, strides=2, padding='same'),\n",
    "        )(previous_activation),\n",
    "        layers.Conv2D(filters=1024, kernel_size=1, strides=2, padding='same')(previous_activation),\n",
    "    ]),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SeparableConv2D(filters=1024, kernel_size=3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(len(classes), activation='linear'),\n",
    "    layers.Dropout(0.2),\n",
    ")(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.build(input_shape=(None, *shape))\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adadelta(\n",
    "        learning_rate=optimizers.schedules.CosineDecayRestarts(\n",
    "            1.0,\n",
    "            # Decay over 5 epochs and then restart \n",
    "            dataset.training.cardinality().numpy() * 5)),\n",
    "    loss=losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.03),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "if os.path.exists('isthemountainout.best.h5'):\n",
    "    print('loading weights from best')\n",
    "    model.load_weights('isthemountainout.best.h5')\n",
    "elif os.path.exists('isthemountainout.h5'):\n",
    "    print('loading weights from saved model')\n",
    "    model.load_weights('isthemountainout.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.8382\n",
      "Epoch 1: val_loss improved from inf to 0.48249, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 155s 454ms/step - loss: 0.4856 - accuracy: 0.8382 - val_loss: 0.4825 - val_accuracy: 0.8760\n",
      "Epoch 2/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8394\n",
      "Epoch 2: val_loss improved from 0.48249 to 0.41030, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 139s 446ms/step - loss: 0.4869 - accuracy: 0.8394 - val_loss: 0.4103 - val_accuracy: 0.9082\n",
      "Epoch 3/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.8439\n",
      "Epoch 3: val_loss improved from 0.41030 to 0.31749, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 139s 445ms/step - loss: 0.4633 - accuracy: 0.8439 - val_loss: 0.3175 - val_accuracy: 0.9114\n",
      "Epoch 4/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8592\n",
      "Epoch 4: val_loss did not improve from 0.31749\n",
      "311/311 [==============================] - 139s 447ms/step - loss: 0.4430 - accuracy: 0.8592 - val_loss: 0.3282 - val_accuracy: 0.9211\n",
      "Epoch 5/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8459\n",
      "Epoch 5: val_loss improved from 0.31749 to 0.30930, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4413 - accuracy: 0.8459 - val_loss: 0.3093 - val_accuracy: 0.9275\n",
      "Epoch 6/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.8390\n",
      "Epoch 6: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 143s 460ms/step - loss: 0.4798 - accuracy: 0.8390 - val_loss: 0.5957 - val_accuracy: 0.7343\n",
      "Epoch 7/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.8467\n",
      "Epoch 7: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 145s 465ms/step - loss: 0.4650 - accuracy: 0.8467 - val_loss: 0.3552 - val_accuracy: 0.9195\n",
      "Epoch 8/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.8455\n",
      "Epoch 8: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 145s 464ms/step - loss: 0.4692 - accuracy: 0.8455 - val_loss: 1.4500 - val_accuracy: 0.5894\n",
      "Epoch 9/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.8487\n",
      "Epoch 9: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4636 - accuracy: 0.8487 - val_loss: 0.3603 - val_accuracy: 0.8905\n",
      "Epoch 10/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8471\n",
      "Epoch 10: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 143s 459ms/step - loss: 0.4674 - accuracy: 0.8471 - val_loss: 0.3338 - val_accuracy: 0.9211\n",
      "Epoch 11/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.8487\n",
      "Epoch 11: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 146s 469ms/step - loss: 0.4403 - accuracy: 0.8487 - val_loss: 0.3351 - val_accuracy: 0.9163\n",
      "Epoch 12/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.8596\n",
      "Epoch 12: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 145s 464ms/step - loss: 0.4387 - accuracy: 0.8596 - val_loss: 0.3461 - val_accuracy: 0.8986\n",
      "Epoch 13/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.8547\n",
      "Epoch 13: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 143s 459ms/step - loss: 0.4335 - accuracy: 0.8547 - val_loss: 0.3099 - val_accuracy: 0.9195\n",
      "Epoch 14/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.8511\n",
      "Epoch 14: val_loss improved from 0.30930 to 0.30877, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 145s 465ms/step - loss: 0.4435 - accuracy: 0.8511 - val_loss: 0.3088 - val_accuracy: 0.9179\n",
      "Epoch 15/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.8668\n",
      "Epoch 15: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 145s 464ms/step - loss: 0.4149 - accuracy: 0.8668 - val_loss: 0.3090 - val_accuracy: 0.9179\n",
      "Epoch 16/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.8539\n",
      "Epoch 16: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4684 - accuracy: 0.8539 - val_loss: 0.4589 - val_accuracy: 0.8760\n",
      "Epoch 17/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.8354\n",
      "Epoch 17: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4780 - accuracy: 0.8354 - val_loss: 0.4377 - val_accuracy: 0.8824\n",
      "Epoch 18/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.8507\n",
      "Epoch 18: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 137s 439ms/step - loss: 0.4681 - accuracy: 0.8507 - val_loss: 0.3474 - val_accuracy: 0.9114\n",
      "Epoch 19/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.8475\n",
      "Epoch 19: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 139s 444ms/step - loss: 0.4720 - accuracy: 0.8475 - val_loss: 1.1991 - val_accuracy: 0.4863\n",
      "Epoch 20/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8499\n",
      "Epoch 20: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 140s 449ms/step - loss: 0.4544 - accuracy: 0.8499 - val_loss: 0.6944 - val_accuracy: 0.7118\n",
      "Epoch 21/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4479 - accuracy: 0.8584\n",
      "Epoch 21: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 141s 453ms/step - loss: 0.4479 - accuracy: 0.8584 - val_loss: 0.3285 - val_accuracy: 0.9211\n",
      "Epoch 22/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8519\n",
      "Epoch 22: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 140s 448ms/step - loss: 0.4487 - accuracy: 0.8519 - val_loss: 0.3993 - val_accuracy: 0.8728\n",
      "Epoch 23/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.8479\n",
      "Epoch 23: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 139s 447ms/step - loss: 0.4518 - accuracy: 0.8479 - val_loss: 0.3609 - val_accuracy: 0.8969\n",
      "Epoch 24/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8519\n",
      "Epoch 24: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 139s 444ms/step - loss: 0.4492 - accuracy: 0.8519 - val_loss: 0.3429 - val_accuracy: 0.9147\n",
      "Epoch 25/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.8563\n",
      "Epoch 25: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 141s 451ms/step - loss: 0.4346 - accuracy: 0.8563 - val_loss: 0.3163 - val_accuracy: 0.9211\n",
      "Epoch 26/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.8535\n",
      "Epoch 26: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 179s 574ms/step - loss: 0.4464 - accuracy: 0.8535 - val_loss: 0.3312 - val_accuracy: 0.9147\n",
      "Epoch 27/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.8616\n",
      "Epoch 27: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 175s 560ms/step - loss: 0.4255 - accuracy: 0.8616 - val_loss: 0.3218 - val_accuracy: 0.9227\n",
      "Epoch 28/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8624\n",
      "Epoch 28: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 118s 379ms/step - loss: 0.4243 - accuracy: 0.8624 - val_loss: 0.3124 - val_accuracy: 0.9195\n",
      "Epoch 29/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8632\n",
      "Epoch 29: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 118s 377ms/step - loss: 0.4264 - accuracy: 0.8632 - val_loss: 0.6068 - val_accuracy: 0.7585\n",
      "Epoch 30/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.8632\n",
      "Epoch 30: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 118s 377ms/step - loss: 0.4138 - accuracy: 0.8632 - val_loss: 0.3149 - val_accuracy: 0.9211\n",
      "Epoch 31/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.8720\n",
      "Epoch 31: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 121s 386ms/step - loss: 0.4024 - accuracy: 0.8720 - val_loss: 0.3319 - val_accuracy: 0.9227\n",
      "Epoch 32/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.8596\n",
      "Epoch 32: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 120s 385ms/step - loss: 0.4144 - accuracy: 0.8596 - val_loss: 0.3171 - val_accuracy: 0.9179\n",
      "Epoch 33/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8664\n",
      "Epoch 33: val_loss improved from 0.30877 to 0.30370, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4166 - accuracy: 0.8664 - val_loss: 0.3037 - val_accuracy: 0.9195\n",
      "Epoch 34/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8696\n",
      "Epoch 34: val_loss improved from 0.30370 to 0.30131, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4030 - accuracy: 0.8696 - val_loss: 0.3013 - val_accuracy: 0.9195\n",
      "Epoch 35/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.8604\n",
      "Epoch 35: val_loss improved from 0.30131 to 0.30063, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4180 - accuracy: 0.8604 - val_loss: 0.3006 - val_accuracy: 0.9211\n",
      "Epoch 36/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8459\n",
      "Epoch 36: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 382ms/step - loss: 0.4601 - accuracy: 0.8459 - val_loss: 0.4739 - val_accuracy: 0.8132\n",
      "Epoch 37/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8471\n",
      "Epoch 37: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 120s 385ms/step - loss: 0.4487 - accuracy: 0.8471 - val_loss: 0.3169 - val_accuracy: 0.9308\n",
      "Epoch 38/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.8491\n",
      "Epoch 38: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 121s 386ms/step - loss: 0.4576 - accuracy: 0.8491 - val_loss: 0.3303 - val_accuracy: 0.9179\n",
      "Epoch 39/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8447\n",
      "Epoch 39: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4609 - accuracy: 0.8447 - val_loss: 0.3378 - val_accuracy: 0.9098\n",
      "Epoch 40/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8535\n",
      "Epoch 40: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4575 - accuracy: 0.8535 - val_loss: 0.3457 - val_accuracy: 0.9034\n",
      "Epoch 41/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.8608\n",
      "Epoch 41: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4470 - accuracy: 0.8608 - val_loss: 0.7121 - val_accuracy: 0.6973\n",
      "Epoch 42/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.8495\n",
      "Epoch 42: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4625 - accuracy: 0.8495 - val_loss: 0.3795 - val_accuracy: 0.9066\n",
      "Epoch 43/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8531\n",
      "Epoch 43: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4399 - accuracy: 0.8531 - val_loss: 0.3484 - val_accuracy: 0.9163\n",
      "Epoch 44/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.8567\n",
      "Epoch 44: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 383ms/step - loss: 0.4570 - accuracy: 0.8567 - val_loss: 0.3180 - val_accuracy: 0.9259\n",
      "Epoch 45/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.8535\n",
      "Epoch 45: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 118s 377ms/step - loss: 0.4476 - accuracy: 0.8535 - val_loss: 0.3943 - val_accuracy: 0.8905\n",
      "Epoch 46/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.8539\n",
      "Epoch 46: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 118s 379ms/step - loss: 0.4458 - accuracy: 0.8539 - val_loss: 0.3288 - val_accuracy: 0.9227\n",
      "Epoch 47/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.8483\n",
      "Epoch 47: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 117s 375ms/step - loss: 0.4401 - accuracy: 0.8483 - val_loss: 0.3132 - val_accuracy: 0.9243\n",
      "Epoch 48/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8596\n",
      "Epoch 48: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 118s 378ms/step - loss: 0.4281 - accuracy: 0.8596 - val_loss: 0.3063 - val_accuracy: 0.9147\n",
      "Epoch 49/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8584\n",
      "Epoch 49: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 117s 375ms/step - loss: 0.4326 - accuracy: 0.8584 - val_loss: 0.4014 - val_accuracy: 0.8889\n",
      "Epoch 50/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4441 - accuracy: 0.8696\n",
      "Epoch 50: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 116s 373ms/step - loss: 0.4441 - accuracy: 0.8696 - val_loss: 0.3143 - val_accuracy: 0.9163\n",
      "Epoch 51/700\n",
      "175/311 [===============>..............] - ETA: 45s - loss: 0.4190 - accuracy: 0.8614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Taylor\\Documents\\sandbox\\isthemountainout\\v2\\trainer\\Model.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     dataset\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m700\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mdataset\u001b[39m.\u001b[39;49mvalidation,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39misthemountainout.best.h5\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             patience\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTensorBoard(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m             log_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m'\u001b[39;49m\u001b[39mtensor-logs\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, datetime\u001b[39m.\u001b[39;49mnow()\u001b[39m.\u001b[39;49mstrftime(\u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m%\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m'\u001b[39;49m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             update_freq\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m             write_images\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             write_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m             embeddings_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     ])\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model.fit(\n",
    "    dataset.training,\n",
    "    epochs=700,\n",
    "    verbose=True,\n",
    "    validation_data=dataset.validation,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'isthemountainout.best.h5',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join('tensor-logs', 'fit', datetime.now().strftime('%Y%m%d%H%M%S')),\n",
    "            update_freq=50,\n",
    "            write_images=True,\n",
    "            write_graph=True,\n",
    "            embeddings_freq=10),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model with best weights\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('loading model with best weights')\n",
    "model.load_weights('isthemountainout.best.h5')\n",
    "\n",
    "validations = dataset.validation\n",
    "predictions = []\n",
    "labels = []\n",
    "for data, label in validations:\n",
    "  labels.append(tf.argmax(label, axis=1))\n",
    "  predictions.append(tf.math.argmax(tf.nn.softmax(model.predict(data, verbose=0)), axis=1))\n",
    "labels = tf.concat(labels, axis=0)\n",
    "predictions = tf.concat(predictions, axis=0)\n",
    "print(labels, predictions)\n",
    "cm = confusion_matrix(labels, predictions, labels=list(range(len(dataset.validation.class_names))))\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "sns.heatmap(\n",
    "  cmn,\n",
    "  annot=True,\n",
    "  fmt='.2f',\n",
    "  xticklabels=dataset.validation.class_names,\n",
    "  yticklabels=dataset.validation.class_names)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mountain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "675b856ca8a14374dc4009cf40e9ead9d95917e285fd3b96229cb66bb660ef16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
