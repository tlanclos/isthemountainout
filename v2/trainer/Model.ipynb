{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling memory growth on PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "%run setup/GpuOptions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3106 files belonging to 4 classes.\n",
      "Using 2485 files for training.\n",
      "Found 3106 files belonging to 4 classes.\n",
      "Using 621 files for validation.\n",
      "loading weights from best\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1920, 1080,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " random_translation_2 (RandomTr  (None, 1920, 1080,   0          ['input_3[0][0]']                \n",
      " anslation)                     3)                                                                \n",
      "                                                                                                  \n",
      " random_brightness_2 (RandomBri  (None, 1920, 1080,   0          ['random_translation_2[0][0]']   \n",
      " ghtness)                       3)                                                                \n",
      "                                                                                                  \n",
      " cropping2d_2 (Cropping2D)      (None, 1410, 50, 3)  0           ['random_brightness_2[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 705, 25, 32)  896         ['cropping2d_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 705, 25, 32)  128        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 705, 25, 32)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 705, 25, 64)  18496       ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 705, 25, 64)  256        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 705, 25, 64)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 705, 25, 64)  0           ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " separable_conv2d_70 (Separable  (None, 705, 25, 128  8896       ['activation_76[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 705, 25, 128  512        ['separable_conv2d_70[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 705, 25, 128  0           ['batch_normalization_76[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_71 (Separable  (None, 705, 25, 128  17664      ['activation_77[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 705, 25, 128  512        ['separable_conv2d_71[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 353, 13, 128  0          ['batch_normalization_77[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 353, 13, 128  8320        ['activation_73[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 353, 13, 128  0           ['max_pooling2d_8[0][0]',        \n",
      "                                )                                 'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 353, 13, 128  0           ['add_24[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_72 (Separable  (None, 353, 13, 256  34176      ['activation_78[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 353, 13, 256  1024       ['separable_conv2d_72[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 353, 13, 256  0           ['batch_normalization_78[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_73 (Separable  (None, 353, 13, 256  68096      ['activation_79[0][0]']          \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 353, 13, 256  1024       ['separable_conv2d_73[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 177, 7, 256)  0          ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 177, 7, 256)  33024       ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 177, 7, 256)  0           ['max_pooling2d_9[0][0]',        \n",
      "                                                                  'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 177, 7, 256)  0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_74 (Separable  (None, 177, 7, 728)  189400     ['activation_80[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 177, 7, 728)  2912       ['separable_conv2d_74[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 177, 7, 728)  0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_75 (Separable  (None, 177, 7, 728)  537264     ['activation_81[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 177, 7, 728)  2912       ['separable_conv2d_75[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 89, 4, 728)  0           ['batch_normalization_81[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 89, 4, 728)   187096      ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 89, 4, 728)   0           ['max_pooling2d_10[0][0]',       \n",
      "                                                                  'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 89, 4, 728)   0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_76 (Separable  (None, 89, 4, 728)  537264      ['activation_82[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_76[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_77 (Separable  (None, 89, 4, 728)  537264      ['activation_83[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_77[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_78 (Separable  (None, 89, 4, 728)  537264      ['activation_84[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_78[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_84[0][0]', \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 89, 4, 728)   0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_79 (Separable  (None, 89, 4, 728)  537264      ['activation_85[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_79[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_80 (Separable  (None, 89, 4, 728)  537264      ['activation_86[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_80[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_81 (Separable  (None, 89, 4, 728)  537264      ['activation_87[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_81[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_87[0][0]', \n",
      "                                                                  'add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 89, 4, 728)   0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_82 (Separable  (None, 89, 4, 728)  537264      ['activation_88[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_82[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_83 (Separable  (None, 89, 4, 728)  537264      ['activation_89[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_83[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_84 (Separable  (None, 89, 4, 728)  537264      ['activation_90[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_84[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_90[0][0]', \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 89, 4, 728)   0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_85 (Separable  (None, 89, 4, 728)  537264      ['activation_91[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_85[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_86 (Separable  (None, 89, 4, 728)  537264      ['activation_92[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_86[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_87 (Separable  (None, 89, 4, 728)  537264      ['activation_93[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_87[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_93[0][0]', \n",
      "                                                                  'add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 89, 4, 728)   0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_88 (Separable  (None, 89, 4, 728)  537264      ['activation_94[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_88[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_89 (Separable  (None, 89, 4, 728)  537264      ['activation_95[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_89[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_90 (Separable  (None, 89, 4, 728)  537264      ['activation_96[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_90[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_96[0][0]', \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 89, 4, 728)   0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_91 (Separable  (None, 89, 4, 728)  537264      ['activation_97[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_91[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_92 (Separable  (None, 89, 4, 728)  537264      ['activation_98[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_92[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 89, 4, 728)   0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_93 (Separable  (None, 89, 4, 728)  537264      ['activation_99[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 89, 4, 728)  2912        ['separable_conv2d_93[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_99[0][0]', \n",
      "                                                                  'add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 89, 4, 728)   0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_94 (Separable  (None, 89, 4, 728)  537264      ['activation_100[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_94[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_95 (Separable  (None, 89, 4, 728)  537264      ['activation_101[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_95[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_96 (Separable  (None, 89, 4, 728)  537264      ['activation_102[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_96[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_102[0][0]',\n",
      "                                                                  'add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 89, 4, 728)   0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_97 (Separable  (None, 89, 4, 728)  537264      ['activation_103[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_97[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_98 (Separable  (None, 89, 4, 728)  537264      ['activation_104[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_98[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_99 (Separable  (None, 89, 4, 728)  537264      ['activation_105[0][0]']         \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_99[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 89, 4, 728)   0           ['batch_normalization_105[0][0]',\n",
      "                                                                  'add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 89, 4, 728)   0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_100 (Separabl  (None, 89, 4, 728)  537264      ['activation_106[0][0]']         \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 89, 4, 728)  2912        ['separable_conv2d_100[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 89, 4, 728)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " separable_conv2d_101 (Separabl  (None, 89, 4, 1024)  753048     ['activation_107[0][0]']         \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 89, 4, 1024)  4096       ['separable_conv2d_101[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 45, 2, 1024)  0          ['batch_normalization_107[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 45, 2, 1024)  746496      ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 45, 2, 1024)  0           ['max_pooling2d_11[0][0]',       \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 45, 2, 1024)  0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_68 (Separable  (None, 45, 2, 728)  755416      ['activation_74[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 45, 2, 728)  2912        ['separable_conv2d_68[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 45, 2, 728)   0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_69 (Separable  (None, 45, 2, 1024)  753048     ['activation_75[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 45, 2, 1024)  4096       ['separable_conv2d_69[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 1024)        0           ['batch_normalization_75[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4)            4100        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,640,220\n",
      "Trainable params: 17,593,628\n",
      "Non-trainable params: 46,592\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, optimizers, losses\n",
    "import common.model as m\n",
    "from common.dataset import Dataset\n",
    "\n",
    "dataset = Dataset(\n",
    "    '../dataset/dataset-2022-10-19T22-51-08',\n",
    "    batch_size=8,\n",
    "    image_size=(1920, 1080))\n",
    "augmentation = [\n",
    "    layers.RandomTranslation(0.05, 0.05, fill_mode='nearest'),\n",
    "    layers.RandomBrightness(0.025),\n",
    "    # Cropping2D parameter are how much to take off of top, bottom, \n",
    "    # left and right, not a rectangle of the cropped image\n",
    "    layers.Cropping2D(cropping=((160, 350), (580, 450))),\n",
    "]\n",
    "classes = dataset.training.class_names\n",
    "data, _ = next(iter(dataset.training))\n",
    "shape = data[0].shape\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "\n",
    "outputs = m.chained(\n",
    "    # Augmentations\n",
    "    *augmentation,\n",
    "    # Entry Flow\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    m.expand(\n",
    "        flow=lambda previous_activation, size: layers.add([\n",
    "            m.chained(\n",
    "                m.duplicate(\n",
    "                    layers=lambda: [\n",
    "                        layers.Activation('relu'),\n",
    "                        layers.SeparableConv2D(filters=size, kernel_size=3, padding='same'),\n",
    "                        layers.BatchNormalization(),\n",
    "                    ],\n",
    "                    count=2\n",
    "                ),\n",
    "                layers.MaxPooling2D(pool_size=3, strides=2, padding='same'),\n",
    "            )(previous_activation),\n",
    "            layers.Conv2D(filters=size, kernel_size=1, strides=2, padding='same')(previous_activation),\n",
    "        ]),\n",
    "        values=[128, 256, 728],\n",
    "    ),\n",
    "\n",
    "    # Middle Flow\n",
    "    m.expand(\n",
    "        flow=lambda previous_activation, _: layers.add([\n",
    "            m.duplicate(\n",
    "                layers=lambda: [\n",
    "                    layers.Activation('relu'),\n",
    "                    layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "                    layers.BatchNormalization(),\n",
    "                ],\n",
    "                count=3,\n",
    "            )(previous_activation),\n",
    "            previous_activation,\n",
    "        ]),\n",
    "        values=[0] * 8\n",
    "    ),\n",
    "\n",
    "    # Exit Flow\n",
    "    lambda previous_activation: layers.add([\n",
    "        m.chained(\n",
    "            layers.Activation('relu'),\n",
    "            layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.SeparableConv2D(filters=1024, kernel_size=3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(pool_size=3, strides=2, padding='same'),\n",
    "        )(previous_activation),\n",
    "        layers.Conv2D(filters=1024, kernel_size=1, strides=2, padding='same')(previous_activation),\n",
    "    ]),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SeparableConv2D(filters=728, kernel_size=3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SeparableConv2D(filters=1024, kernel_size=3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(len(classes), activation='linear'),\n",
    "    layers.Dropout(0.2),\n",
    ")(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.build(input_shape=(None, *shape))\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adadelta(\n",
    "        learning_rate=optimizers.schedules.CosineDecayRestarts(\n",
    "            1.0,\n",
    "            # Decay over 5 epochs and then restart \n",
    "            dataset.training.cardinality().numpy() * 5)),\n",
    "    loss=losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.03),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "if os.path.exists('isthemountainout.best.h5'):\n",
    "    print('loading weights from best')\n",
    "    model.load_weights('isthemountainout.best.h5')\n",
    "elif os.path.exists('isthemountainout.h5'):\n",
    "    print('loading weights from saved model')\n",
    "    model.load_weights('isthemountainout.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.8382\n",
      "Epoch 1: val_loss improved from inf to 0.48249, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 155s 454ms/step - loss: 0.4856 - accuracy: 0.8382 - val_loss: 0.4825 - val_accuracy: 0.8760\n",
      "Epoch 2/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8394\n",
      "Epoch 2: val_loss improved from 0.48249 to 0.41030, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 139s 446ms/step - loss: 0.4869 - accuracy: 0.8394 - val_loss: 0.4103 - val_accuracy: 0.9082\n",
      "Epoch 3/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.8439\n",
      "Epoch 3: val_loss improved from 0.41030 to 0.31749, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 139s 445ms/step - loss: 0.4633 - accuracy: 0.8439 - val_loss: 0.3175 - val_accuracy: 0.9114\n",
      "Epoch 4/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8592\n",
      "Epoch 4: val_loss did not improve from 0.31749\n",
      "311/311 [==============================] - 139s 447ms/step - loss: 0.4430 - accuracy: 0.8592 - val_loss: 0.3282 - val_accuracy: 0.9211\n",
      "Epoch 5/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8459\n",
      "Epoch 5: val_loss improved from 0.31749 to 0.30930, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4413 - accuracy: 0.8459 - val_loss: 0.3093 - val_accuracy: 0.9275\n",
      "Epoch 6/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.8390\n",
      "Epoch 6: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 143s 460ms/step - loss: 0.4798 - accuracy: 0.8390 - val_loss: 0.5957 - val_accuracy: 0.7343\n",
      "Epoch 7/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.8467\n",
      "Epoch 7: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 145s 465ms/step - loss: 0.4650 - accuracy: 0.8467 - val_loss: 0.3552 - val_accuracy: 0.9195\n",
      "Epoch 8/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.8455\n",
      "Epoch 8: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 145s 464ms/step - loss: 0.4692 - accuracy: 0.8455 - val_loss: 1.4500 - val_accuracy: 0.5894\n",
      "Epoch 9/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.8487\n",
      "Epoch 9: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4636 - accuracy: 0.8487 - val_loss: 0.3603 - val_accuracy: 0.8905\n",
      "Epoch 10/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8471\n",
      "Epoch 10: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 143s 459ms/step - loss: 0.4674 - accuracy: 0.8471 - val_loss: 0.3338 - val_accuracy: 0.9211\n",
      "Epoch 11/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.8487\n",
      "Epoch 11: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 146s 469ms/step - loss: 0.4403 - accuracy: 0.8487 - val_loss: 0.3351 - val_accuracy: 0.9163\n",
      "Epoch 12/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.8596\n",
      "Epoch 12: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 145s 464ms/step - loss: 0.4387 - accuracy: 0.8596 - val_loss: 0.3461 - val_accuracy: 0.8986\n",
      "Epoch 13/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.8547\n",
      "Epoch 13: val_loss did not improve from 0.30930\n",
      "311/311 [==============================] - 143s 459ms/step - loss: 0.4335 - accuracy: 0.8547 - val_loss: 0.3099 - val_accuracy: 0.9195\n",
      "Epoch 14/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.8511\n",
      "Epoch 14: val_loss improved from 0.30930 to 0.30877, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 145s 465ms/step - loss: 0.4435 - accuracy: 0.8511 - val_loss: 0.3088 - val_accuracy: 0.9179\n",
      "Epoch 15/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.8668\n",
      "Epoch 15: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 145s 464ms/step - loss: 0.4149 - accuracy: 0.8668 - val_loss: 0.3090 - val_accuracy: 0.9179\n",
      "Epoch 16/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.8539\n",
      "Epoch 16: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4684 - accuracy: 0.8539 - val_loss: 0.4589 - val_accuracy: 0.8760\n",
      "Epoch 17/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.8354\n",
      "Epoch 17: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 144s 463ms/step - loss: 0.4780 - accuracy: 0.8354 - val_loss: 0.4377 - val_accuracy: 0.8824\n",
      "Epoch 18/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.8507\n",
      "Epoch 18: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 137s 439ms/step - loss: 0.4681 - accuracy: 0.8507 - val_loss: 0.3474 - val_accuracy: 0.9114\n",
      "Epoch 19/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.8475\n",
      "Epoch 19: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 139s 444ms/step - loss: 0.4720 - accuracy: 0.8475 - val_loss: 1.1991 - val_accuracy: 0.4863\n",
      "Epoch 20/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8499\n",
      "Epoch 20: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 140s 449ms/step - loss: 0.4544 - accuracy: 0.8499 - val_loss: 0.6944 - val_accuracy: 0.7118\n",
      "Epoch 21/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4479 - accuracy: 0.8584\n",
      "Epoch 21: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 141s 453ms/step - loss: 0.4479 - accuracy: 0.8584 - val_loss: 0.3285 - val_accuracy: 0.9211\n",
      "Epoch 22/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8519\n",
      "Epoch 22: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 140s 448ms/step - loss: 0.4487 - accuracy: 0.8519 - val_loss: 0.3993 - val_accuracy: 0.8728\n",
      "Epoch 23/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.8479\n",
      "Epoch 23: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 139s 447ms/step - loss: 0.4518 - accuracy: 0.8479 - val_loss: 0.3609 - val_accuracy: 0.8969\n",
      "Epoch 24/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8519\n",
      "Epoch 24: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 139s 444ms/step - loss: 0.4492 - accuracy: 0.8519 - val_loss: 0.3429 - val_accuracy: 0.9147\n",
      "Epoch 25/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.8563\n",
      "Epoch 25: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 141s 451ms/step - loss: 0.4346 - accuracy: 0.8563 - val_loss: 0.3163 - val_accuracy: 0.9211\n",
      "Epoch 26/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.8535\n",
      "Epoch 26: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 179s 574ms/step - loss: 0.4464 - accuracy: 0.8535 - val_loss: 0.3312 - val_accuracy: 0.9147\n",
      "Epoch 27/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.8616\n",
      "Epoch 27: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 175s 560ms/step - loss: 0.4255 - accuracy: 0.8616 - val_loss: 0.3218 - val_accuracy: 0.9227\n",
      "Epoch 28/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8624\n",
      "Epoch 28: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 118s 379ms/step - loss: 0.4243 - accuracy: 0.8624 - val_loss: 0.3124 - val_accuracy: 0.9195\n",
      "Epoch 29/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8632\n",
      "Epoch 29: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 118s 377ms/step - loss: 0.4264 - accuracy: 0.8632 - val_loss: 0.6068 - val_accuracy: 0.7585\n",
      "Epoch 30/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.8632\n",
      "Epoch 30: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 118s 377ms/step - loss: 0.4138 - accuracy: 0.8632 - val_loss: 0.3149 - val_accuracy: 0.9211\n",
      "Epoch 31/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.8720\n",
      "Epoch 31: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 121s 386ms/step - loss: 0.4024 - accuracy: 0.8720 - val_loss: 0.3319 - val_accuracy: 0.9227\n",
      "Epoch 32/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.8596\n",
      "Epoch 32: val_loss did not improve from 0.30877\n",
      "311/311 [==============================] - 120s 385ms/step - loss: 0.4144 - accuracy: 0.8596 - val_loss: 0.3171 - val_accuracy: 0.9179\n",
      "Epoch 33/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8664\n",
      "Epoch 33: val_loss improved from 0.30877 to 0.30370, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4166 - accuracy: 0.8664 - val_loss: 0.3037 - val_accuracy: 0.9195\n",
      "Epoch 34/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8696\n",
      "Epoch 34: val_loss improved from 0.30370 to 0.30131, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4030 - accuracy: 0.8696 - val_loss: 0.3013 - val_accuracy: 0.9195\n",
      "Epoch 35/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.8604\n",
      "Epoch 35: val_loss improved from 0.30131 to 0.30063, saving model to isthemountainout.best.h5\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4180 - accuracy: 0.8604 - val_loss: 0.3006 - val_accuracy: 0.9211\n",
      "Epoch 36/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8459\n",
      "Epoch 36: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 382ms/step - loss: 0.4601 - accuracy: 0.8459 - val_loss: 0.4739 - val_accuracy: 0.8132\n",
      "Epoch 37/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8471\n",
      "Epoch 37: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 120s 385ms/step - loss: 0.4487 - accuracy: 0.8471 - val_loss: 0.3169 - val_accuracy: 0.9308\n",
      "Epoch 38/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.8491\n",
      "Epoch 38: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 121s 386ms/step - loss: 0.4576 - accuracy: 0.8491 - val_loss: 0.3303 - val_accuracy: 0.9179\n",
      "Epoch 39/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8447\n",
      "Epoch 39: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4609 - accuracy: 0.8447 - val_loss: 0.3378 - val_accuracy: 0.9098\n",
      "Epoch 40/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8535\n",
      "Epoch 40: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4575 - accuracy: 0.8535 - val_loss: 0.3457 - val_accuracy: 0.9034\n",
      "Epoch 41/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.8608\n",
      "Epoch 41: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 120s 384ms/step - loss: 0.4470 - accuracy: 0.8608 - val_loss: 0.7121 - val_accuracy: 0.6973\n",
      "Epoch 42/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.8495\n",
      "Epoch 42: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4625 - accuracy: 0.8495 - val_loss: 0.3795 - val_accuracy: 0.9066\n",
      "Epoch 43/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8531\n",
      "Epoch 43: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 381ms/step - loss: 0.4399 - accuracy: 0.8531 - val_loss: 0.3484 - val_accuracy: 0.9163\n",
      "Epoch 44/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.8567\n",
      "Epoch 44: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 119s 383ms/step - loss: 0.4570 - accuracy: 0.8567 - val_loss: 0.3180 - val_accuracy: 0.9259\n",
      "Epoch 45/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.8535\n",
      "Epoch 45: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 118s 377ms/step - loss: 0.4476 - accuracy: 0.8535 - val_loss: 0.3943 - val_accuracy: 0.8905\n",
      "Epoch 46/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.8539\n",
      "Epoch 46: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 118s 379ms/step - loss: 0.4458 - accuracy: 0.8539 - val_loss: 0.3288 - val_accuracy: 0.9227\n",
      "Epoch 47/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.8483\n",
      "Epoch 47: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 117s 375ms/step - loss: 0.4401 - accuracy: 0.8483 - val_loss: 0.3132 - val_accuracy: 0.9243\n",
      "Epoch 48/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8596\n",
      "Epoch 48: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 118s 378ms/step - loss: 0.4281 - accuracy: 0.8596 - val_loss: 0.3063 - val_accuracy: 0.9147\n",
      "Epoch 49/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8584\n",
      "Epoch 49: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 117s 375ms/step - loss: 0.4326 - accuracy: 0.8584 - val_loss: 0.4014 - val_accuracy: 0.8889\n",
      "Epoch 50/700\n",
      "311/311 [==============================] - ETA: 0s - loss: 0.4441 - accuracy: 0.8696\n",
      "Epoch 50: val_loss did not improve from 0.30063\n",
      "311/311 [==============================] - 116s 373ms/step - loss: 0.4441 - accuracy: 0.8696 - val_loss: 0.3143 - val_accuracy: 0.9163\n",
      "Epoch 51/700\n",
      "175/311 [===============>..............] - ETA: 45s - loss: 0.4190 - accuracy: 0.8614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Taylor\\Documents\\sandbox\\isthemountainout\\v2\\trainer\\Model.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     dataset\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m700\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mdataset\u001b[39m.\u001b[39;49mvalidation,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39misthemountainout.best.h5\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             patience\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTensorBoard(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m             log_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m'\u001b[39;49m\u001b[39mtensor-logs\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, datetime\u001b[39m.\u001b[39;49mnow()\u001b[39m.\u001b[39;49mstrftime(\u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m%\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m'\u001b[39;49m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             update_freq\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m             write_images\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             write_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m             embeddings_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Taylor/Documents/sandbox/isthemountainout/v2/trainer/Model.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     ])\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Taylor\\anaconda3\\envs\\mountain\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model.fit(\n",
    "    dataset.training,\n",
    "    epochs=700,\n",
    "    verbose=True,\n",
    "    validation_data=dataset.validation,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'isthemountainout.best.h5',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=True),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join('tensor-logs', 'fit', datetime.now().strftime('%Y%m%d%H%M%S')),\n",
    "            update_freq=50,\n",
    "            write_images=True,\n",
    "            write_graph=True,\n",
    "            embeddings_freq=10),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model with best weights\n",
      "Found 3106 files belonging to 4 classes.\n",
      "Using 2485 files for training.\n",
      "Found 3106 files belonging to 4 classes.\n",
      "Using 621 files for validation.\n",
      "78/78 [==============================] - 12s 138ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEoCAYAAAAwkAR+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABk1klEQVR4nO3dd1QU19vA8e+yVGnSwa4xKnaFRDGvLbZoEkuKxt4VNfYSjbGbYG8x9tiNGluixkQx9tgRS+wFxQJSrKi0Zd4/+Lm6sCBLgIX1+XjmHPbunTt3xoVn78wtKkVRFIQQQog8zszYFRBCCCGyggQ0IYQQJkECmhBCCJMgAU0IIYRJkIAmhBDCJEhAE0IIYRIkoAkhhDAJEtCEEEKYBAloQgghTIIENCGEECZBApoQQgiTYG7sCmQHc8uCxq5CnnS3xrvGrkKeU/DwVWNXIU96ce+gsauQ51i4lsjS8hKibhjt2NnFaAHt7NmzGc5bsWLFbKyJEEK8hZI0xq5BljNaQKtcuTIqlYq0Jvt/+Z5KpUKjMb0LL4QQRqVJNHYNspzRAlpISIixDi2EEG89RUkydhWynNECWtGiRY11aCGEEEkS0LLFypUr032/Q4cOOVQTIYR4S2RzC23evHlMnTqVsLAwypUrx6xZs6hZs2aa+ePi4hg/fjyrV68mPDycQoUKMXLkSLp06ZLhY+aKgNa/f3+d1wkJCTx//hxLS0vy5csnAU0IIbJaNnYKWb9+PQMGDGDevHl88MEHLFy4kMaNG3PhwgWKFCmid5+WLVty//59fv75Z0qWLElERASJiYY951MpafXKMLKrV6/Sq1cvhg4dSqNGjQzaV7rtZ4502zecdNvPHOm2b7is7joff/NkhvNaFvM1qOxq1apRtWpV5s+fr03z9vamefPmBAQEpMr/119/8dVXX3Hjxg2cnZ0NOtbrcu3A6nfffZdJkyalar0JIYTIAklJGd7i4uJ48uSJzhYXF6e32Pj4eIKCgmjYsKFOesOGDTl8+LDefbZu3Yqvry9TpkyhYMGClCpViiFDhvDixQuDTinXBjQAtVrNvXv3jF0NIYQwOYqSlOEtICAAR0dHnU1fSwsgKioKjUaDh4eHTrqHhwfh4eF697lx4waHDh3i33//ZcuWLcyaNYuNGzfSp08fg84pVzxD27p1q85rRVEICwtj7ty5fPDBB0aqlRBCmDADejmOGDGCQYMG6aRZWVmlu49KpdJ5/XJcsf6qJKFSqVizZg2Ojo4AzJgxgy+++IKffvoJGxubDNUzVwS05s2b67xWqVS4ubnx4YcfMn36dONUSgghTJkmIcNZrays3hjAXnJ1dUWtVqdqjUVERKRqtb3k5eVFwYIFtcEMkp+5KYrCnTt3ePfdjD3fN9otxydPnmh/TkpK0tk0Gg3h4eH88ssveHl5GauKQghhupSkjG8GsLS0xMfHh8DAQJ30wMBAatSooXefDz74gHv37hETE6NNu3LlCmZmZhQqVCjDxzZaQHNyciIiIgKADz/8kEePHhmrKkII8fYxoFOIoQYNGsSSJUtYunQpFy9eZODAgYSGhuLv7w8k38J8fThWmzZtcHFxoXPnzly4cIEDBw4wdOhQunTpkuHbjWDEW452dnZER0fj7u7Ovn37SEjIePNXCCHEf5SNA6tbtWpFdHQ048ePJywsjPLly7Njxw7tDFFhYWGEhoZq89vZ2REYGEjfvn3x9fXFxcWFli1bMnHiRIOOa7RxaJ9//jn//PMP3t7e7N+/nxo1amBpaak37549ewwqW8ahZY6MQzOcjEPLHBmHZrisHocWd3ZnhvNaVTRsLLCxGK2Ftnr1alasWMH169fZv38/5cqVI1++fMaqjhBCvFUUxfRWMTFaQLOxsdHeTz158iSTJ08mf/78xqqOEEK8XWS2/eyxd+9eY1dBCCHeLjLbftYZNGgQEyZMwNbWNtWAvZRmzJiRQ7USQoi3hLTQsk5wcLC2Z+OpU6fSHEEuhBAiGxgwsDqvMFpAe/024759+4xVDSGEeDuZ4C3HXDE5cZcuXXj69Gmq9GfPnhm0uJsQQogMyqaZQowpVwS0FStW6F0m4MWLF29czdqY/Ht25OrlI8Q8uc6xo3/yfx+8n27+WjWrc+zon8Q8uc6VS4fp0b19qjwtWjTh7Jm9PHt6g7Nn9tKs2UfZVX2jsWnWDNe1a3HftQvnhQuxqFAhzbwWFSrg9OOPuP3+O+47d+KyciX5vvgiVb58X3yBy8qVuO/cieuvv2LXpw+kMa4xL5LPWuas27ydRl90omrdprTs0peg0/+mmz8+Pp7ZC5fT4LOOVKnzKR992ZnN21+N19q49U869BpCjY++pMZHX9Kt/wjOXbic3aeRPbJxphBjMWpAe/LkCY8fP0ZRFJ4+faqz1s7Dhw/ZsWMH7u7uxqximr78sikzpo8lYNIcfN9vxKFDx9m+bTWFCxfQm79YscJs27qKQ4eO4/t+IyZN/pFZM8fTokUTbZ7q1XxYu2Y+a9ZsoqpvA9as2cS6Xxbw/ntVcuq0sp1V3brYf/01z1avJrpbN+LPnSP/lCmYpfH/rLx4wYstW3jQvz9RHTvybNUq7Lp2xeaTT7R5rOvXx65HD56tWEFUx448mTIF67p1sevePadOK1vJZy1z/ty9n0mzF9K9w1dsWDaXqhXL4T9kFGHhEWnuM3hUAMdOnmb8iAFsX7uEqeOGU7xoYe37J06dpUmDOiydM4nVC2fg6eFGj4EjuR8ZlROnlLVMMKAZdcVqMzOzdDuDqFQqxo0bx8iRIw0qNydmCjl8aBungv/l674jtGnnzu5j69a/GPndpFT5A374lk8+aUiFinW0aT/NnUSlimX5v1pNAfhlzXwc7O34pOmrb9N/bFvNw0ePadfesHWBMiMnZgpxnjePhKtXeTpzpjbNZcUK4g4dImbx4gyV4Th+PEpsLE9++AEA+/79URcpwqPBg7V57Hr1wsLbm4f9+mXtCaSQEzOFmOJnLSdmCmndfQDepd5h9NC+2rRP2/Tgw5p+DOzVOVX+Q0dPMnTMJP7asAxHB/sMHUOj0VDjoy/5dlBvmjWun2V11yerZwp5cWB5hvPa1OqUpcfOLkZtoe3du5e///4bRVHYuHEje/bs0W6HDh0iNDTU4GCWEywsLKhatSKBu/frpAcG7sevuv6lyqtX8yEwUDf/rsB9+PhUxNzc/FWe3QdS5Em7zDzH3Bzz0qWJP3FCJzn+xAksypXLWBElS2JRvjwJZ8682v/cOSxKl8a8TBkA1F5eWFWvTtzRo1lXdyORz1rmJCQkcOHyVWq8X1Unvcb7VTnz7wW9++w9dJRyZd5l6ZoNfNisHR9/1Y2pcxcTm8bKzACxsXEkJmoyHABzFRNsoRl1YHXt2rUBCAkJoUiRInmm676rqzPm5uZE3Ne9zRAREYWHp/5bZx6e7kREpMh/PwoLCwtcXZ0JD4/A09ON+xGROnnuR0Ti6emWtSdgJGaOjqjUapIePtRJ1zx8iKWzc7r7um7YgJmjI6jVPFu+nBd//KF9L27PHmIcHXH+8UdQqVCZm/P8t994/ssv2XIeOUk+a5nz8NETNJokXJyddNJdnPITFf1Q7z537oVz6ux5LC0tmR0wioePHjNx+k88fvKUid/qHys7c8Ey3N1c8PPNg7dq81Bnj4zKFTOF3Lp1i1u3bqX5fq1atdJ8Ly4ujrgU36DSWxk1K6W8W6tSqVKlpZ8/dbqhZeZJes7xTR707YuZjQ0WZcti16MHmrt3if3fpNUWlStj2749T2fNIuHCBdQFC2Lfty9J0dE8W7UqW04hp8lnLXNSrZrMG1ZNRsXkMcOwt7MFYGh8AoO++57vBvfBOsUCl0vXbGBH4D6WzZ2ClVUe7ICUh1peGZUrAlqdOnVSpb3+odNo0p5EMyAggHHjxunua2aHSu2QZfVLKSrqAYmJiXik+Dbr5uZCxP1IvfvcD4/AwyNFfndXEhISiP7fN8bw8Eg8PXS/dbu7uXL/fh584KxH0uPHKBoNZilaY2b585P04EH6+4aHkwQkhoRg5uyMbadO2oBm16ULsbt2aVttiSEhqGxscBg8mGerV6cKoHmJfNYyxym/A2q1GVHRup+rBw8f4+KcX+8+bi7OuLu5aIMZQIlihVEUhfsRURQt/OrZ/LJfNrJ45XoWz/qB0iWLZ8s5ZDtNorFrkOVyRbf9hw8f6mwRERH89ddfvPfee+zatSvdfUeMGMHjx491NpVZ9t7PTkhI4NSps9Svp9tyrF+/FkeOntS7z9FjQdSvr5u/Qf3aBAWdJTEx8VWeejVT5Em7zDwnMZHEy5ex9NV9TmPp60vC+fMGFaV6rUu+ysoq9bdNjSa5WZJHbmOnRT5rmWNhYUHZ0u9y5ESwTvqRE6eoVL6s3n2qVCxLZNQDnj9/NYTo1u27mJmZ4eHuqk1bumYjC5evZcH0CZT3LpU9J5ATTHAcWq5ooTk6OqZKa9CgAVZWVgwcOJCgoKA097WyssIqxa2AnLjdOHP2YlYsm01Q0BmOHguie9d2FClckIWLkm9xfT9xOAUKeNG5S38AFi5aRe9enZk2ZQxLlq6hejUfunT+irav9Sj78cef2btnE0OH9Gbrtp00/bQR9erVpHadFtl+Pjnl2YYNOH77LQmXL5Nw/jw2n36KmYcHz7duBcCue3fMXF15EhAAgE3z5mju30fzv8UALSpUIF+rVjzfskVbZtyRI+T78ksSrl0j4cIFzAsWxLZrV+L++cckbqvIZy1zOrRqwYgJ0yhX5l0qlfdm4+9/EnY/klb/G74wc/4yIqKiCRg1BICPG9RlwfK1fPfDDPp0bcfDx0+Y/tPPtPi4ofZ249I1G/hx8UqmjPmGgl4e2hZgPhsb8uXL+MrKuYIJ/G6klCsCWlrc3Ny4fDl3DlrcsGErLs5OfDdyIF5e7vx7/jKfNm1PaOhdADw9PSjy2jihmzdv82nT9kybNpZevTpy7959BgwczZYtO7R5jhw9SZt2vRk/bhjjxg7l+o1btG7bi+MpvmXmZXF79/LUwQG7jh0xc3YmMSSER998Q9L9+wCYubig9vB4tYNKhX2PHqg9PVE0GjT37hGzaBEvtm3TZnm2ahUoCnZdu6J2dSXp0SPiDh8m5uefc/r0soV81jKncf3aPH7ylAXLfiEy+gHvlijG/GnjKeCZ/PmKin5A2P1XY9Ly5bNh8awf+GHGfFp17Y+joz0ffViLvj06aPOs27ydhIREBn73vc6xenVpS5+u7XLmxLKKCQY0o45De+ns2bM6rxVFISwsjEmTJpGQkMA///xjUHmyYnXmyIrVhpMVqzNHVqw2XJaPQ9ue8VVMbD5Jf0WU3CJXtNAqV66st4dV9erVWbp0qZFqJYQQJswEW2i5IqCFhITovDYzM8PNzQ1ra2sj1UgIIUxcHurskVG5IqAVLVrU2FUQQoi3i7TQss+zZ8/Yv38/oaGhxMfH67zXL5vn4xNCiLeOtNCyR3BwME2aNOH58+c8e/YMZ2dnoqKiyJcvH+7u7hLQhBAiq5lgCy1XDKweOHAgn376KQ8ePMDGxoajR49y69YtfHx8mDZtmrGrJ4QQpkejyfiWR+SKgHb69GkGDx6MWq1GrVYTFxdH4cKFmTJlCt9++62xqyeEEKbHBGfbzxUBzcLCQju7h4eHB6H/mxXC0dFR+7MQQogsJAEte1SpUoWTJ5PnkKtbty6jR49mzZo1DBgwgAoVKhi5dkIIYYKyeS7HefPmUbx4caytrfHx8eHgwbQH0+/btw+VSpVqu3TpkkHHzBUB7YcffsDLywuACRMm4OLiQq9evYiIiGDRokVGrp0QQpigbGyhrV+/ngEDBjBy5EiCg4OpWbMmjRs3fuMdt8uXLxMWFqbd3n3XsNmLckUvR9/XZl93c3Njx44d6eQWQgjxn2XjrIczZsyga9eudOvWDYBZs2axc+dO5s+fT8D/Jh7Xx93dnfz582f6uLmihQaQmJjI7t27WbhwIU+fPgXg3r17xMTEGLlmQghhggxoocXFxfHkyROdLeXCyi/Fx8cTFBREw4YNddIbNmzI4cOH061SlSpV8PLyol69euzdu9fgU8oVAe3WrVtUqFCBZs2a0adPHyIjkxcunDJlCkOGDDFy7YQQwgQZENACAgJwdHTU2dJqaUVFRaHRaPB4fdUMkjv8hYeH693Hy8uLRYsWsWnTJjZv3kzp0qWpV68eBw4cMOiUcsUtx/79++Pr68uZM2dwcXHRprdo0ULbZBVCCJGFDOjsMWLECAYN0p1xP+U6lCmlXJdSUZQ016osXbo0pUuX1r728/Pj9u3bTJs2jVq1aundR59cEdAOHTrEP//8g+VrqxBD8hyPd+/eNVKthBDCdCmJGR8wrW8h5bS4urqiVqtTtcYiIiJStdrSU716dVavXp3h/JBLbjkmJSWh0TMa/c6dO9jb2xuhRkIIYeKyqdu+paUlPj4+BAYG6qQHBgZSo0aNDJcTHBys7f2eUbmihdagQQNmzZql7aKvUqmIiYlhzJgxNGnSxMi1E0IIE5SUfb0cBw0aRPv27fH19cXPz49FixYRGhqKv78/kHwL8+7du6xcuRJI7gVZrFgxypUrR3x8PKtXr2bTpk1s2rTJoOPmioA2c+ZM6tatS9myZYmNjaVNmzZcvXoVFxcX1q5da+zqCSGE6cnGGUBatWpFdHQ048ePJywsjPLly7Njxw7tUmFhYWE6Y9Li4+MZMmQId+/excbGhnLlyvHHH38Y3KBRKSmXiTaSFy9esHbtWk6dOkVSUhJVq1albdu22NjYGFyWuWXBbKih6btbw7BBjAIKHr5q7CrkSS/upT1rhNDPwrVElpb3fLZ/hvPm678gS4+dXXLFM7To6GhsbGzo0qULw4YNw9XVlcuXL2unwxJCCJHFFCXjWx5h1IB27tw5ihUrhru7O2XKlOH06dO8//77zJw5k0WLFlG3bl1+++03Y1ZRCCFMk0xOnLWGDRtGhQoV2L9/P3Xq1OGTTz6hSZMmPH78mIcPH9KzZ08mTZpkzCoKIYRpSlIyvuURRu0UcuLECfbs2UPFihWpXLkyixYtonfv3piZJcfZvn37Ur16dWNWUQghTFMmZ9HPzYwa0B48eICnpycAdnZ22Nra4uzsrH3fyclJO6+jIczSGI0u0ufQs7axq5DnFDz3wNhVyJNix35t7CrkORZzs3bSdkMGVucVRu+2n3IqlLSmRhFCCJGF8tCtxIwyekDr1KmTdkqV2NhY/P39sbW1BUhzNmchhBD/kdxyzFodO3bUed2uXbtUeTp06JBT1RFCiLeHtNCy1rJly4x5eCGEeHvloe74GWX0W45CCCGMQFpoQgghTII8QxNCCGESpIUmhBDCFCjyDC17xcfHExERQVKKC12kSBEj1UgIIUxUogS0bHH16lW6dOnC4cOHddIVRUGlUuldzVoIIcR/IM/QskenTp0wNzdn+/bteHl5yWwhQgiR3eQZWvY4ffo0QUFBlClTxthVEUKIt4IiAS17lC1blqioKGNXQwgh3h4mGNByxYrVkydPZtiwYezbt4/o6GiePHmiswkhhMhiJrjAZ65oodWvXx+AevXq6aRLpxAhhMgmJthCyxUBbe/evcaughBCvF0koGWP2rVlYUkhhMhJimJ6AS1XPEMDOHjwIO3ataNGjRrcvXsXgFWrVnHo0CEj10wIIUxQkpLxLY/IFQFt06ZNNGrUCBsbG06dOqVd2PPp06f88MMPRq6dEEKYHiUxKcNbXpErAtrEiRNZsGABixcvxsLCQpteo0YNTp06ZcSaCSGEiTLBFlqueIZ2+fJlatWqlSrdwcGBR48e5XyFhBDC1OWdhleG5YoWmpeXF9euXUuVfujQIUqUKGGEGgkhhGlTkpQMb5kxb948ihcvjrW1NT4+Phw8eDBD+/3zzz+Ym5tTuXJlg4+ZKwJaz5496d+/P8eOHUOlUnHv3j3WrFnDkCFD6N27t7GrJ4QQpicbbzmuX7+eAQMGMHLkSIKDg6lZsyaNGzcmNDQ03f0eP35Mhw4dUo1JzqhcEdCGDRtG8+bNqVu3LjExMdSqVYtu3brRs2dPvv76a2NXL009e3bg8uXDPHl8jaNHdvDBB++nm79mzeocPbKDJ4+vcenSP3Tv3k7n/bLepVi/bhFXLh8hPu4Offt2zc7qG83641dpMmsb70/4ldYLd3LqVkSaeU+E3Kfy2HWptpDIVzPIXIt4zOD1h2g8cyuVx65j9ZHLOXEaOap9l1YcOvUnl++eYPvf63ivetV081er4cP2v9dx+e4JDgbtoG2nL3Xe/6J1U25Fn021WVlZZudp5DiLmh9jO3YpdjN/I9+w2ajfKZeh/dQlymI3exv5hv+ok25eqQb5hs3Gbsqv2E3fTL7hP2L+3ofZUfXsl2TAZqAZM2bQtWtXunXrhre3N7NmzaJw4cLMnz8/3f169uxJmzZt8PPzM/yg5JJnaADff/89I0eO5MKFCyQlJVG2bFns7OyMXa00ffnFp0yfNpa+/UZy5MgJunVrx7atq6hUuS63b99Llb9YscJs/X0lPy/9hU6d++Hn9x4/zvmeqMgHbPltBwA2+Wy4ERLKpk3bmTp1TE6fUo7Y+W8oU/8K5tuPfahcxJWNJ6/TZ/UBNvdpjFd+2zT3+/3rJthaveow5GRrpf05NiGRgk52NChbmGk7g7O1/sbwSfNGjP5+GKOGfs/J48G06fglK9bPo36N5ty7G54qf+EiBVm+bh5rV21iQK8R+L5fhQlTR/Ig+iF/btutzffkyVM+rNZUZ9+4uPhsP5+cYl61Flaf9yBu/Tw0Ny5g8X+Nsek9nmcT/VEeRqa9o3U+rNsPRnPlNCr7/DpvKc+fEv/XOpLu30HRJGBevhrW7QbyIuYRmot5qwObIbcS4+LitL3PX7KyssLKyipV3vj4eIKCghg+fLhOesOGDVMtEfa6ZcuWcf36dVavXs3EiRMzXLfX5YoW2kv58uXD19eX999/P1cHM4D+/XuwbPk6li1by6VL1xgyZCx37tyjZ48OevP36N6e27fvMmTIWC5dusayZWtZvmI9Awf21OYJCjrDiBET+XXDVpP6w/K6VUcu0aJqCT7zeYcSbo4Ma1wVT8d8bDiZ+hnq65xsrXG1t9FuarNXH93yBV0Y1LAyH1UoioU6V32ks0S33h1Yv2YL61Zv5tqVEMaPnELYvXDadWmpN3/bzl9y724Y40dO4dqVENat3syva7bQo09HnXyKohAZEa2zmRLLD1uQcGQXCUd2knT/NnGbFpH0MBKLmh+nu591674knNyHJuRSqvc0V8+RePYISfdvo0SFk7Dvd5LuhaAukbGWX65iQAstICAAR0dHnS0gIEBvsVFRUWg0Gjw8PHTSPTw8CA9P/QUMktfEHD58OGvWrMHcPPPtLKO10D777LMM5928eXM21sRwFhYWVK1agalTf9JJD9x9gOrVffXuU61aVQJ3H9DNv2s/nTt9hbm5OYmJidlW39wiIVHDxXsP6fJ/ZXXSq7/jyZnb6a+28NXCncQnaijh5kD3WuV4r7hHuvlNhYWFORUqeTN/9s866Qf2HsHnvcp696nqW4kDe4+kyH+YVu1a6HzWbG3z8c/pv1Cr1Vw4d4npAT9x/lzqP+J5ktocs8Ilid/1q06y5mIw6uLeae5mXr0BZq5exK6YiuVHrd98mFKVMHMvhOb6sv9c5ZxmSAttxIgRDBo0SCdNX+vsdSnXtXw5N29KGo2GNm3aMG7cOEqVKpXhOuljtIDm6Oio/VlRFLZs2YKjoyO+vskBISgoiEePHr0x8OlrCqd14bKKq6sz5ubm3I/QvW0RcT8ST083vft4eroTsWufTtr9iEgsLCxwdXUmPDzt50im4uHzeDSKgrOttU66i60VUTGxevdxs7dh1KfvUdbLiXhNEtvP3KTHir0s6fQhPsXcc6LaRuXk4oS5uTlRKVpPUZHRuHm46t3Hzd2FqMgU+SOisbCwwNklPxH3o7h+9SZDvh7FpQtXsbO3o0vPtmzasYKPan/JzRvpP7jPC1R2DqjUapKePtJJV54+xMzBSf8+bgWwatqJ57OGpT/DvHU+7L5fBeYWkJRE7Pqf0FzKe7e6FQO+Q6d1e1EfV1dX1Gp1qtZYREREqlYbJE+gcfLkSYKDg7V9JpKSklAUBXNzc3bt2sWHH2bsOaXRAtqyZa++0XzzzTe0bNmSBQsWoFargeSo3bt3bxwcHNItJyAggHHjxumkmZnZozZPf7+skHIuNJVKle78aPry60s3dSm/ayhAWl8/irk6UMz11f9lpcKu3H/ynJWHL70VAe2lrP6sBZ88S/DJs9r3Tx4L5o+96+nUvTVjR0zOqmrnAimuUVrXTWWGTadhxO9YgxJxN/0i417wLOBrVFY2qEtXwvqz7ryIDkdz9VzWVTsnZNM4NEtLS3x8fAgMDKRFixba9MDAQJo1a5Yqv4ODA+fO6V67efPmsWfPHjZu3Ejx4sUzfOxc0Slk6dKlHDp0SBvMANRqNYMGDaJGjRpMnTo1zX31NYVdXNO+pZAVoqIekJiYiKeH7h9UN3dX7t/Xf+ssPDwCD0/d/O5uriQkJBAd/TDb6pqbOOWzRK1SEZ2iNfbgWRwudtZp7JVahUIu7Dh7K6urlys9jH5IYmJiqtaYi6tzqlbbS5ER0bi5p8jv5kxCQgIPHzzWu4+iKJwNPk/xEkWzpuJGpsQ8QdFoMLN30vm7rbLLj5Ki1QaAtQ3qoqUwK/QOVl/2+l9mFSozM+xmb+PFT9+huXLmf4UrKFFhKEDS3RuYeRbBsmFLXuSxgKZk48DqQYMG0b59e3x9ffHz82PRokWEhobi7+8PJP/dvnv3LitXrsTMzIzy5cvr7O/u7o61tXWq9DfJFQEtMTGRixcvUrp0aZ30ixcvkvSGxeX0NYWz83YjQEJCAqdOnaNe/Zr8vvUvbXr9ejXZtm2X3n2OHTvFxx/X10mr36AWQUFn34rnZwAW5mq8Czhx5Ho4H3oX0qYfux5OnTIFM1zO5bCHuBoQAPOyhIREzp25SM06fuz8Y482vWad6uz6U/+yS6dOnqF+I90VLGrWrcG50xfS/ayVrVCayxeuZk3FjU2TSNLta6jLVCHx7KvnieoyVUg8dzR1/tjnPPu+l06SRc2PUZeqROzPP5AUrb8zg5a5Rfrv50bZGNBatWpFdHQ048ePJywsjPLly7Njxw6KFk3+whQWFvbGMWmZkSsCWufOnenSpQvXrl2jevXqABw9epRJkybRuXNnI9dOv9mzF7Fs2WyCgs5y7FgQXbu2pXDhgixavAqAiROGU6CAJ126DgBg0eJV9OrViSlTRrN06S9Uq+ZD505f0b79q3F2FhYWlPV+FwBLSwsKFPCiUsWyxDx7zvXrN3P6FLNFe78yjNx8lHIFnKlY2IVNQdcJe/ycL3xLAjBn9xkinrxg4mfJn4PVRy5TIL8t77g7kqBJYsfZm+y+eIfpLT/QlpmQqOH6/8alJWqSiHj6gkthD8lnaU4RF/ucP8kstmTeSmbO/4Gzwec5dfIMrTt8QYGCXqxZtgGAYaP64enlwaDeIwFYs2wDHbu2ZtSEIaxdtYmqvpVo1bYF/Xp8oy2z/1B/gk+eJeTGLezt7ejcow1ly5dm1DDTmQw8fs8WrDsMRhN6laSQS1h88BFmzm4kHEweJmPZtBNmji7ErpoOikJSmG6rX4l5DInxOumWDVsmlxcZhsrcHHW597CoVo+4dbodxPKC7GyhAfTu3TvNiTGWL1+e7r5jx45l7NixBh8zVwS0adOm4enpycyZMwkLCwOSp8MaNmwYgwcPNnLt9NuwcRvOLk6M/HYAXl7unD9/mabNOhAamnz/3dPTncKFX7U6bt68TdNmHZg2dQy9/DtyL+w+AweN1o5BAyhQwIMTJ1618AYP8mfwIH/27z9Cg4a6A2Pzqkbli/DoeRwL9/9LVEwsJd0dmdu2FgX+NwYt8ukLwh4/0+ZP0CQxc9dpIp6+wMpczTvuDvzYphY1SxXQ5ol4+oKvFu7Uvl55+FLyM7aibvzcOXMzDuQm23/biZNzfvoN7Ym7hxtXLl6j01d9uHsn+XfF3cONAgU9tflvh96l01e9GT1xGO27fkVEeCRjR0zSGYPm4GhPwMzRuLm78vRJDOfPXaTlJ505c+rfHD+/7JJ46gBxtvZYNW6DysGZpLCbvJg3BuVhcgcsMwcnVM76O3GlydIa65a9UeV3hYR4ku7fJnbFNBJPHXjzvrlMdgc0Y1ApuaxHwpMnyd+039QZJD2WVoXenEmk8ni5ac5Mkp3KfL3F2FXIk/5tLb+jhrKfu+PNmQxwv27GF1b22Ls/S4+dXXJFC+11/yWQCSGEyCAle/saGIPRAlqVKlUy3HlD1kQTQoisZYq3HI0W0Jo3b679OTY2lnnz5lG2bFntpJRHjx7l/PnzMtu+EEJkg6REaaFlmTFjXk2+261bN/r168eECRNS5bl9+3ZOV00IIUyeYoK3HHPFTK4bNmygQ4fUk/q2a9eOTZs2GaFGQghh2pSkjG95RYZaaFu3bs1wgU2bNn1zphRsbGw4dOgQ7777rk76oUOHsLZ+OwbQCiFETlKSTK+FlqGA9vrzrvSoVCo0Go3BlRgwYAC9evUiKChIZ2D10qVLGT16tMHlCSGESF/uGrCVNTIU0N40/dR/NXz4cEqUKMHs2bP55ZdfAPD29mb58uW0bKl/zSchhBCZ99a20HJCy5YtJXgJIUQOkYD2P8+ePWP//v2EhoYSH6+7snK/fv2ypGJCCCGyz1t7y/F1wcHBNGnShOfPn/Ps2TOcnZ2JiooiX758uLu7ZzigOTs7c+XKFVxdXXFyckp3kPWDBw8MraYQQoh0SAsNGDhwIJ9++inz588nf/78HD16FAsLC9q1a0f//v0zXM7MmTOxt7fX/pzdS74IIYR4JUljen9zDQ5op0+fZuHChajVatRqNXFxcZQoUYIpU6bQsWNHPvvsswyV07FjR548eUJcXFyG9xFCCJE1kkxwYLXBAc3CwkLbmvLw8CA0NBRvb28cHR0NXrAtf/78GWqZZWYogBBCiLSZ4kwhBge0KlWqcPLkSUqVKkXdunUZPXo0UVFRrFq1igoVKhhU1t69r1bcVRSFJk2asGTJEgoWzPjqxUIIIQwnz9CAH374gadPnwIwYcIEOnbsSK9evShZsiTLli0zqKzatXXX41Gr1VSvXp0SJUoYWi0hhBAGkF6OgK+vr/ZnNzc3duzI2kXnhBBCZD9poQkhhDAJ0ikEKF68eLodOW7cuPGfKiTd94UQIvtJpxCSJxJ+XUJCAsHBwfz1118MHTrUoLJSdtePjY3F398fW1tbnfTNmzcbWk0hhBDpkGdokObg6Z9++omTJ08aVJajo6PO63bt2hlaHSGEEJkgtxzT0bhxY0aMGGFQT0dDe0UKIYTIGknSKSRtGzduxNnZOauKE0IIkY2khUbywOrXO24oikJ4eDiRkZHMmzcvSyuXWUmmeHM4J7jLgHZDNbEvY+wq5ElHN5jeH9Ps1mBu1pYnnUKAZs2a6QQ0MzMz3NzcqFOnDmXKyC+3EELkBdndQps3bx5Tp04lLCyMcuXKMWvWLGrWrKk376FDh/jmm2+4dOkSz58/p2jRovTs2ZOBAwcadEyDA9rYsWMN3UUIIUQuk533sdavX8+AAQOYN28eH3zwAQsXLqRx48ZcuHCBIkWKpMpva2vL119/TcWKFbG1teXQoUP07NkTW1tbevTokeHjmhlaUbVaTURERKr06Oho1Gq1ocUJIYQwgiRFleHNUDNmzKBr165069YNb29vZs2aReHChZk/f77e/FWqVKF169aUK1eOYsWK0a5dOxo1asTBgwcNOq7BAU1J4/lUXFwclpaWhhYnhBDCCBRFleEtLi6OJ0+e6GxxcXF6y42PjycoKIiGDRvqpDds2JDDhw9nqG7BwcEcPnw41Xy/b5LhW45z5swBkmfyWLJkCXZ2dtr3NBoNBw4cMOgZ2qBBgzKcd8aMGRnOK4QQ4s2SDMgbEBDAuHHjdNLGjBmj9xFUVFQUGo0GDw8PnXQPDw/Cw8PTPU6hQoWIjIwkMTGRsWPH0q1bNwNqaUBAmzlzJpDcQluwYIHO7UVLS0uKFSvGggULMnzg4ODgDOWTqbCEECLrKWT8b+uIESNSNUKsrKzS3Sfl325FUd749/zgwYPExMRw9OhRhg8fTsmSJWndunWG65nhgBYSEgJA3bp12bx5M05OThk+iD6vr4UmhBAiZyUa8GzMysrqjQHsJVdXV9RqdarWWERERKpWW0rFixcHoEKFCty/f5+xY8caFNAMfoa2d+/e/xzMhBBCGJeCKsObISwtLfHx8SEwMFAnPTAwkBo1amS8foqS5nO6tBjcbf+LL77A19eX4cOH66RPnTqV48ePs2HDBkOLBODEiRNs2LCB0NBQ4uPjdd6TyYmFECJrGfIMzVCDBg2iffv2+Pr64ufnx6JFiwgNDcXf3x9IvoV59+5dVq5cCSTPBVykSBFtP4xDhw4xbdo0+vbta9BxDQ5o+/fvZ8yYManSP/roI6ZNm2ZocQCsW7eODh060LBhQwIDA2nYsCFXr14lPDycFi1aZKpMIYQQaTO05WWIVq1aER0dzfjx4wkLC6N8+fLs2LGDokWLAhAWFkZoaKg2f1JSEiNGjCAkJARzc3PeeecdJk2aRM+ePQ06rkpJqx9+GmxsbDh9+jSlS5fWSb906RJVqlThxYsXBlUAoGLFivTs2ZM+ffpgb2/PmTNnKF68OD179sTLyytV75o3MbeUKZwy4+mfqb+oiPQN6rrb2FXIkz57IZ29DNXg/vosLe8vj68ynPej++uy9NjZxeBnaOXLl2f9+tQXdt26dZQtWzZTlbh+/Toff/wxkPzw8dmzZ6hUKgYOHMiiRYsyVaYQQoi0JRmw5RUG33IcNWoUn3/+OdevX+fDDz8E4O+//+aXX35h48aNmaqEs7MzT58+BaBgwYL8+++/VKhQgUePHvH8+fNMlSmEECJt2XnL0VgMDmhNmzblt99+44cffmDjxo3Y2NhQqVIl9uzZg4ODQ6YqUbNmTQIDA6lQoQItW7akf//+7Nmzh8DAQOrVq5epMoUQQqTNBJdDy9x6aB9//LH2FuGjR49Ys2YNAwYM4MyZM2g0GoPLmzt3LrGxsUBy7xcLCwsOHTrEZ599xqhRozJTRSGEEOlIkhbaK3v27GHp0qVs3ryZokWL8vnnn/Pzzz9nqqzXFwY1MzNj2LBhDBs2LLNVE0II8QaGNz1yP4MC2p07d1i+fDlLly7l2bNntGzZkoSEBDZt2pTpDiEAO3bsQK1W06hRI530Xbt2odFoaNy4cabLFkIIkVqSCU4rmOFejk2aNKFs2bJcuHCBH3/8kXv37vHjjz9mSSWGDx+u91ZlUlJSqgHcQggh/jvFgC2vyHALbdeuXfTr149evXrx7rvvZmklrl69qreFV6ZMGa5du5alxxJCCJG3uuNnVIZbaAcPHuTp06f4+vpSrVo15s6dS2RkZJZUwtHRkRs3bqRKv3btGra2tllyDCGEEK8kqTK+5RUZDmh+fn4sXryYsLAwevbsybp16yhYsCBJSUkEBgZqx5FlRtOmTRkwYADXr1/Xpl27do3BgwfTtGnTTJcrhBBCvyRUGd7yCoNnCsmXLx9dunTh0KFDnDt3jsGDBzNp0iTc3d0zHXymTp2Kra0tZcqUoXjx4hQvXhxvb29cXFwyPT+kEEKItL3Vz9D0KV26NFOmTCEgIIBt27axdOnSTJXj6OjI4cOHCQwM5MyZM9jY2FCxYkVq1ar1X6onhBAiDXnpVmJG/aeA9pJaraZ58+Y0b94802WoVCoaNmxIw4YNs6JKOcK/Z0cGD/LHy8ud8xeuMHjwGA79czzN/LVqVmfq1DGUK1uKe/fuM236fBYtXqWTp0WLJowbO5R3ShTl+o1bjBo9md9//yu7TyVHrd9/mhW7TxD1+BnveLkw9Mu6VC1ZSG/eE1du033Wr6nSt4zuRHFPFwB+P/IvY1btTJXn2Oz+WFlkyUfc6Gq1a0iDnk1xdM9P2JU7bBi/nGsnLunN6+CWny++60CR8iVwK+7JvuV/smH8Cp08A9eNoVT1cqn2PbfnFPO6TMqWczCGQp0aUqzPp1i65+fZ5TtcHrWCR8f0Xzf3Ju9TqFMD7MsVw8zKnJjLd7gxdSPR+85o86jM1RTv1xyvVrWw8nTm+fUwrk5YQ/TeM3rLzM1MsVOI0X7b58yZQ48ePbC2tmbOnDnp5u3Xr18O1SrjvvyyKTOmj+Xrvt9y+MgJundrz/Ztq6lQqQ63b99Llb9YscJs27qKJT//QsdOfanh9x5zf/yByKhotmzZAUD1aj6sXTOfMWOn8tvvf9K8WWPW/bKA2nVacPxEcE6fYrbYefISUzfu5duv6lG5REE2HjpLn582s3lUJ7yc05467fcxnbG1frVirpO9jc77dtaW/Dami06aqQQzn0/8+HJ0J9aNWsL1k5ep2bY+fZZ/y/gGA3l4LzpVfnMrC54+eMKfP22mXteP9Za5sOc0zC1fXR/b/PaM/HMqp3YcybbzyGkezfwoPaEjl4b/zKPjlynYoT5V1o7gSM1BxN5Nfd3y+3kTvf8c135YR+LjZxRoXYfKq4ZxvPFInv57E4B3hrfC64uaXBy8kGfX7uFSpxKVlg3hxCejtHnyCo0JttAMXj4mqxQvXpyTJ0/i4uKiXXZbH5VKpbcHZHpyYvmYw4e2cSr4X77uO0Kbdu7sPrZu/YuR36X+hhvww7d88klDKlSso037ae4kKlUsy//VSn72+Mua+TjY2/FJ0/baPH9sW83DR49p175P9p3M/+TE8jHtpqzBu7AHI1vX16a1GLeMupVK0q95zVT5X7bQDkzrg0M+a71l/n7kX6Zu3Meh6V9nW73TkhPLxwz77Xtu/xvC2u+WaNNG757BmV0n+H3K2nT3HbhuDHcu3EzVQkvpwy5N+GRgS4a/35P4F4atEpwZObF8zPt/TuTJ2RAuffNqBiO/gzOI/OsE175P/7pp8++fxv3fj3BjxiYAap2Zz41ZW7izbJc2T6XlQ9A8i+XfPnOz9gRSyOrlYxYXapfhvN3vrM7SY2cXo32FDQkJ0ftzXmBhYUHVqhWZPPUnnfTAwP34VffVu0/1aj4EBu7XSdsVuI8unb/C3NycxMREqlfzYfacxSny7Kdf325ZewJGkpCo4WLofbo0fF8nvbp3Uc7cSN2qfd1XAauIT9BQwsuF7h9V473SRXTefxEXT+PvFqFJUihdyJ0+n9agTGGPLD+HnKa2UFOkfAl2zv9NJ/3iwbOU8Cmtf6dMqNHyQ05uO5wjwSwnqCzU2FcsQcic33XSH+w/Q37fUhksRIXazoaERzGvkiwtSIpL0MmWFBtP/vez7v8ip5jiLUeDezlmh/Hjx+tdJubFixeMHz8+3X3j4uJ48uSJzpbdjU5XV2fMzc2JuB+lkx4REYWHp7vefTw83YmISJH/fhQWFha4uibPZenp6cb9CN2xffcjIvH0dMvC2hvPw5gXaJIUnO3z6aS7ONgS9eSZ3n3cHG0Z1aYB07s3ZXqPphR1d6LHnA0EXb2jzVPc05nx7T9iln9zJnX5GCsLNZ2mreNWxMNsPZ+cYOfkgNpczdPIxzrpTyMf4+iaP0uOUbTSOxQsU4R/1v+dJeXlBpbODpiZq4lPcd3iIh9j6Z4/Q2UU7fUJ6nxWhG99dRs2et8Zivb8mHzFPUGlwrlWBdwa+WLl4ZSV1c8RiirjW16RKwLauHHjiImJSZX+/PnzN65WHRAQgKOjo86mJGV+TJwhUgZOlUqVbjBNnT91uqFl5kWqFHPIKYpCWtPKFfNw5vP/q4h3EQ8qlSjAyNb1qVmuBCt3n9DmqVi8AB9XK0vpQu5ULVmIKV0/pYiHE+v2mcZzRwAlZedplZ60TPqg1YfcvRTKrTPX35w5z0n9+0QGfp88W9TgnaFfcK7nbBKinmjTL3+3nOch4dT4Zyb17qyhTEAX7q3bh6LJe+0dU1zgM1cEtOQ/aKn/op05c0ZnJn59RowYwePHj3U2lZl9dlUVgKioByQmJuKRouXk5uZCxH39s6fcD4/AwyNFfndXEhISiI5ObkmEh0fi6aHbwnN3c+V+ipZgXuVkZ4PaTEV0itbYg6fPcbHP+IwwFYp7ERrxKM33zcxUlCvqSagJtNBiHj5Bk6jBwS2/Trq9qyNPoh7r38kAFtaW+H7ygUm1zgDiHzwhKVGDZYrrZunqkKrVlpJHMz/KzvDnbPdZPDhwTue9hOinnOk0jT3FO3DIpw+HPxhI4rNYXoRGZPUpZDsJaFnMyckJZ2dnVCoVpUqVwtnZWbs5OjrSoEEDWrZsmW4ZVlZWODg46Gz6gmNWSkhI4NSps9SvpztOrn79Whw5elLvPkePBVG/vm7+BvVrExR0lsTExFd56tVMkSftMvMaC3M13kU8OHLxlk76sUu3qFSiQIbLuXwnAlfHtAOgoihcvp1+nrxCk6Ah9N8beP9fRZ107/+ryI2gy/+5fJ9P/DC3Muf4loP/uazcREnQ8PTsDVxq614351oVeXTySpr7ebaoQbnZvTnXew5Ru9Nu4SfFJRAX/hCVuRqPT6oRuTPv/Y7KwOosNmvWLBRFoUuXLowbNw5HR0fte5aWlhQrVgw/Pz8j1jBtM2cvZsWy2QQFneHosSC6d21HkcIFWbgoeVzZ9xOHU6CAF5279Adg4aJV9O7VmWlTxrBk6RqqV/OhS+evaPta78Uff/yZvXs2MXRIb7Zu20nTTxtRr15NatdpYZRzzA7tP/Rh5Io/KVfUg4rFC7Dpn7OEPXzKFzUrATDnt4NEPIphYqfkJYNW7wmigLMD7xRwJSFRw47jF9kdfJXp3V/NSrPgj8NULF6AIu75iXkRz9p9p7hyJ5IRX5nGaud/L9lOpxl9uXX2BiGnrvB/berjVMCVg2sCAWg2rDX5PZxZMfhVJ6VCZYsCYJXPGjtnBwqVLUpifCLh1+7qlP1Byw85s+sEzx6lvuWf191a8Afl537NkzPXeXzyKgXb18O6kCt3ViRft5IjW2Pl6cz5vsnXzbNFDcr92IfL363g8cmrWLol/z1Kio0n8ekLAByqlsTa05mn529i5elMiaFfgJmKm3O3Guck/wMZWJ3FOnbsCCR34f/ggw8wN88744Y2bNiKi7MT340ciJeXO/+ev8ynTdsTGpr8B8PT04MihV+1Om7evM2nTdszbdpYevXqyL179xkwcLR2DBrAkaMnadOuN+PHDWPc2KFcv3GL1m17mcwYNIBGvmV49CyWhTuOEvXkGSW9XJjb+zMKuCSPQYt88oywh6+eWSQkapi55QARj2KwsjDnHS8XfuzdgprlS2jzPH0Rx4RfdhH15Dl21paUKezOz4NaUaGYV46fX3YI2n4E2/z2fNz/cxzcnAi7cpufOgfw4G7yrWhHdyecC7rq7DNyx1Ttz0UrvsP7zWsSfSeC7/7v1dAG9+JelHzfm9ntJuTMieSw+78fwcLJnhKDPsfKw4mYS7cJbjOJ2DvJ183KPT/WBV20+Qu2r4+ZhTnek7viPbmrNv3eun2c7z8fALWVBe8Mb4VNUXc0z2KJ+vs05/v8ROKT1J3acru8dCsxo4w2Du11p06dwsLCggoVKgDw+++/s2zZMsqWLcvYsWOxtLQ0qLycGIdminJiHJqpyYlxaKYoJ8ahmZqsHoc2vUjGx6ENDs0b49ByRaeQnj17cuVK8n3tGzdu0KpVK/Lly8eGDRsYNmyYkWsnhBCmR6PK+JZX5IqAduXKFSpXrgzAhg0bqF27Nr/88gvLly9n06ZNxq2cEEKYIFPs5ZgrHlopikJSUvJl2717N5988gkAhQsXJirKNLqsCyFEbmL0Z03ZIFe00Hx9fZk4cSKrVq1i//79fPxx8oSqISEheHjk/emLhBAit0lCyfCWGfPmzaN48eJYW1vj4+PDwYNpDw3ZvHkzDRo0wM3NDQcHB/z8/Ni5M/UKGm+SKwLazJkzCQoK4uuvv2bkyJGULFkSgI0bN1KjRg0j104IIUxPdt5yXL9+PQMGDGDkyJEEBwdTs2ZNGjduTGhoqN78Bw4coEGDBuzYsYOgoCDq1q3Lp59+SnCwYT28c0Uvx7TExsaiVquxsLAwaD/p5Zg50svRcNLLMXOkl6PhsrqX4/iibTOcd/StNQaVXa1aNapWrcr8+fO1ad7e3jRv3pyAgIAMlVGuXDlatWrF6NGjM3zcXNFC69SpEwcOHEiVbm1tbXAwE0II8WaGtND0TQIfF6d/ZYb4+HiCgoJSLdbcsGFDDh8+nLG6JSXx9OnTN059mFKuCGhPnz6lYcOGvPvuu/zwww/cvXv3zTsJIYTItCRVxjd9k8Cn1dKKiopCo9Gk6v/g4eFBeHh4huo2ffp0nj179sapD1PKFQFt06ZN3L17l6+//poNGzZQrFgxGjduzIYNG0hISHhzAUIIIQxiSKcQfZPAjxgxIt3y9a+q8eZbzWvXrmXs2LGsX78ed3f9y3GlJVcENAAXFxf69+9PcHAwx48fp2TJknTo0IECBQowcOBArl69auwqCiGEydAYsOmbBN7Kykpvua6urqjV6lStsYiIiDf2Wl+/fj1du3bl119/pX79+unm1SfXBLSXwsLC2LVrF7t27UKtVtOkSRPOnz9P2bJlmTlzprGrJ4QQJiG7uu1bWlri4+NDYGCgTnpgYGC6vdbXrl1Lp06d+OWXX7RDtwyVKwZWJyQksHXrVpYtW8auXbuoWLEiAwcOpG3bttjbJ69ttm7dOnr16sXAgQONXFshhMj7srN7+6BBg2jfvj2+vr74+fmxaNEiQkND8ff3B5LXsbx79y4rV64EkoNZhw4dmD17NtWrV9e27mxsbHRWYXmTXBHQvLy80Gg0tGnThuPHj2unwXpdo0aNyJ8/f47XTQghTFF2TmnVqlUroqOjGT9+PGFhYZQvX54dO3ZQtGjyskZhYWE6Y9IWLlxIYmIiffr0oU+fV0tqdezYkeXLl2f4uLliHNqqVav48ssvsba2zpLyZBxa5sg4NMPJOLTMkXFohsvqcWiDin2V4bwzbq7L0mNnF6O20Lp06aL9ee/evWnmW7p0aU5URwgh3hpGb8lkA6MGtOXLl1O0aFGqVKlCLmgoCiHEWyMvzaKfUUYNaP7+/qxbt44bN27QpUsX2rVrZ/DIcCGEEIZTTLCNZtRu+/PmzSMsLIxvvvmGbdu2UbhwYVq2bMnOnTulxSaEENnIFNdDM/o4NCsrK1q3bk1gYCAXLlygXLly9O7dm6JFixITE2Ps6gkhhEnSoGR4yytyRbf9l1QqFSqVSmfBTyGEEFkvs+uc5WZGb6HFxcWxdu1aGjRoQOnSpTl37hxz584lNDQUOzs7Y1dPCCFMkinecjRqC613796sW7eOIkWK0LlzZ9atW4eLi4sxqySEEG8FU+wUYtSAtmDBAooUKULx4sXZv38/+/fv15tv8+bNOVwzIYQwbXmp5ZVRRg1oHTp0yNByAoYyN1NneZlvhZhHxq5BnhMcH2HsKuRJo96RmUKMTVpoWcyQObqEEEJkHWmhCSGEMAlJJjjWVwKaEEK8hUwvnElAE0KIt5LGBG86SkATQoi3kOmFMwloQgjxVjLFmUIkoAkhxFtIuu0LIYQwCXLLUQghhEkwxSW6JKAJIcRbSJ6hCSGEMAlyy1EIIYRJkE4hQgghTIIp3nI0+gKfAGq1moiI1LOWR0dHo1bLzPlCCJHVNIqS4S2vyBUttLR628TFxWFpaZnDtRFCCNMntxyz2Jw5cwBQqVQsWbIEOzs77XsajYYDBw5QpkwZY1VPCCFMlinecjRqQJs5cyaQ3EJbsGCBzu1FS0tLihUrxoIFC4xVPSGEMFnZPQ5t3rx5TJ06lbCwMMqVK8esWbOoWbOm3rxhYWEMHjyYoKAgrl69Sr9+/Zg1a5bBxzRqQAsJCQGgbt26bN68GScnJ2NWRwgh3hrZ2UJbv349AwYMYN68eXzwwQcsXLiQxo0bc+HCBYoUKZIqf1xcHG5ubowcOVLb0MmMXNEpZO/evRLMhBAiBykG/DPUjBkz6Nq1K926dcPb25tZs2ZRuHBh5s+frzd/sWLFmD17Nh06dMDR0THT55QrOoVoNBqWL1/O33//TUREBElJukP+9uzZY6SaCSGEaTJkxeq4uDji4uJ00qysrLCyskqVNz4+nqCgIIYPH66T3rBhQw4fPpy5ymZQrmih9e/fn/79+6PRaChfvjyVKlXS2YQQQmQtxYAtICAAR0dHnS0gIEBvuVFRUWg0Gjw8PHTSPTw8CA8Pz7bzgVzSQlu3bh2//vorTZo0MXZVhBDirWDIM7QRI0YwaNAgnTR9rbPXqVQqndeKoqRKy2q5IqBZWlpSsmRJY1fDYD16tGfQoJ54erpz4cJVhg4dxz//HE8zf82a1Zg8eTRly75LWFgE06cvYMmS1dr3vb1LMXr0IKpWrUDRooUZMmQcc+f+nBOnkqPWH77Aiv3niHr6gnc88jO0aXWqFvfUm/fE9TC6L9yRKn3LkM8p7p4fgL/P3eTnPWcIjX5CoiaJIq4OdKhVnk983s3O08hRn3dsRtteX+Hi7kLIlRBmjp7LmePn0sxfpXol+o/tTfFSxYm6H8XqeevYsmqr9n21uZqOfdvS5MtGuHm6EXo9lJ++X8TRfWl/fvOifJ81w65NK9QuLiSE3OTJ7LnEn9F/3Swrlsehd0/MixZGZW1NYvh9nv+2jWfrN2rzuMydiVXVyqn2jT18lAdDRmTXaWQLjZLx2RzTur2oj6urK2q1OlVrLCIiIlWrLavlioA2ePBgZs+ezdy5c7M9gmeVL774lGnTxtC//3ccPnySbt3a8vvvK6hSpR63b99Llb9YscL89tsKli5dS+fO/alRw5fZsycSFRXNb7/9CUC+fNaEhISyefMfTJkyJqdPKUfsPH2DqduO8W3zGlQu5sHGY5fo8/NONg/+HC8nuzT3+33oF9haW2hfO9laa392yGdFt3qVKOaWHwtzMw5cDGXMhoM429lQo3ShbD2fnFC/aV0GjPuaqd/O4uzxczRv35SZa6bQuk5H7t9NPcOOV2FPZqyexO9r/mDs199T8f0KDP1hAI+iH7F3xwEA/L/pSqPPGhAwdBq3roVSvc57TPp5Aj2a9eHKv9dy+hSzhXW9ujj278PjabOIP/sv+Zp/ivP0yUS27YTmfurrlhQby7NNW0i4dgPlxQssK1XAcdgglNhYnv++HYAHI0ajsnj1Z9PM0RG3FUt4sWdfTp1WlsmuXo6Wlpb4+PgQGBhIixYttOmBgYE0a9YsW475ktEC2meffabzes+ePfz555+UK1cOCwsLnfc2b96ck1XLkH79urF8+XqWLVsHwNCh42jQoBY9erRn1KjJqfJ369aO27fvMnToOAAuX75G1aoVGTCghzagBQWdJSjoLAATJw5PVYYpWHXwX1q8V4rPqpUGYFjT6hy5cocNRy/Sr/F7ae7nZGeNg43+b4jvveOl87rt/5Vn28lrBN+8bxIBrXWPL9m2dgdbf/kDgFlj5lK9znt81qEZ8wMWp8r/WYem3L8bwawxcwG4eS2UMhVL08a/lTagffR5Q5bPWc2RPccA2LxyK9XqvE+bnq0Y2/f7HDqz7GX31Zc837aD59uSW/hPZv+EVbX3yNeiKU8XLEmVP/HKNRKvvArmL8LvY127JpaVKmgDmvL0qU4YsKn/IUpcLLF79mfruWSH7JwpZNCgQbRv3x5fX1/8/PxYtGgRoaGh+Pv7A8m3MO/evcvKlSu1+5w+fRqAmJgYIiMjOX36NJaWlpQtWzbDxzVaQEvZNfP1SJ7bWVhYULVqBaZNm6eTvnv3QapX99G7T/XqVdm9+6BOWmDgfjp1aoW5uTmJiYnZVt/cIiFRw8W7UXSpW1Envfq7BTlzM/U35td9Nes34hM1lPDIT/cPK/NeyQJ68ymKwvFrYdyMfEz/JmkHyLzC3MKc0hVLs3LuLzrpx/afoIJvOb37lPcpx7H9J3Tz7ztO09ZNUJur0SRqsLS0ID4uXidPXGwcld6vkLUnYCzm5liULkXMKt3rFnf8JJYVymesiFIlsaxQnqeL0r7tn+/TJrzYvRclNvY/VdcYsnNgdatWrYiOjmb8+PGEhYVRvnx5duzYQdGiRYHkgdShoaE6+1SpUkX7c1BQEL/88gtFixbl5s2bGT6u0QLasmXLjHXo/8zV1Rlzc3MiIqJ00iMiIvHwcNO7j4eHGxERkSnyR2FhYYGrqzPh4en/QTcFD5/FoklScLaz0Ul3sbch6ukLvfu42dsw6vMPKFvQlXiNhu2nrtFj8Z8s6dkEnxKvWmZPX8TT8Pu1JCRqMDMz49sWNfArVTBbzycn5Hd2xNxczYOohzrpDyIf4uLurHcfFzdnHkSmyB/1EHMLc/I7OxId8YCj+0/QuseXnD56hjs37/FezarUavQBZma5ouPzf2aW3xGVuRrNA93rkPTgIWrn9Me8evz2K2b5HUGt5unPK7QtvJQsvMtg8U4JHv0wNcvqnZOye+qr3r1707t3b73vLV++PFVaVgTYXPEM7b/QNz4iJ3rTvDzO61QqVbr/KSnfellHU1wKPT0p/2sUJXXaS8Xc81Psf50/ACoV9eD+o2es3P+vTkCztbJg/YAWPI9P4PjVe0zbdoyCzvapbkfmVfo/a4blT05Pfj1z1I+MmDaUdQdWoihw99Zdtq//k09aNc7Sehtfyl+6VCmpRPXqh8rGBsvyZXHo1R3N3bu8CEw9Fjbfp01IuH6DhIuXsq66OcgU/+7kioBWpUoVvQFIpVJhbW1NyZIl6dSpE3Xr1k2VJyAggHHjxumkqdUOmJtnfrT5m0RFPSAxMTFVa8zNzTVVq+2l+/dTt97c3FxISEggOvqh3n1MjZOtNWozFdEpWmMPYl7gkqLVlp4KRdzZEazbccHMTEURVwcAyhRwISTiEUv3nsnzAe3Rg8ckJmpwcdNtjTm55udB5AO9+0RHPkjVenNyyU9iQiKPHz7WlvtNl++wtLLE0cmByPAo+ozswb3QsOw5kRyW9OgxSqIGtbMzCa+lmzk5kfQg/d83TVhy77zEGyGYOTth36VjqoCmsrLCpn5dni5ZnsU1zzmmODlxrri/8NFHH3Hjxg1sbW2pW7cuderUwc7OjuvXr/Pee+8RFhZG/fr1+f3331PtO2LECB4/fqyzqdUO2VrfhIQETp06R716uhNt1qtXk6NHg/Tuc/ToqVT569evRVDQ2bfi+RmAhbka74KuHLl6Vyf92NV7VCrmnuFyLt+LxtU+X7p5FCA+UZOZauYqiQmJXD57mfdr+eqkv1/Ll3Mnz+vd59+g86nyV6v9HhfPXEaT4prEx8UTGR6F2lxNnSa1ObDzn6w9AWNJTCTh8hWs3te9Dlbv+RB/7l8DClKBniWsrOvVQWVhyfO/Av9jRY0nO6e+MpZc0UKLiopi8ODBjBo1Sid94sSJ3Lp1i127djFmzBgmTJiQqtunvvEROXG7cc6cJSxdOpNTp85y9OgpunZtQ+HCBVi8OHlc2YQJ31CggCdduw4EYMmS1fTq1ZHJk0exdOlaqlevSqdOrejQoa+2TAsLC7y93/3fz5YUKOBBxYpliYl5xo0bt7L9nHJC+5rlGbl+P+UKuVGxiDubjl0i7FEMX1RPXiZozp8niHj8nIlf1QZg9cF/KeBkxzseTiRoktgRfI3d524yvX09bZk/7zlD2UKuFHaxJ0GTxKFLt9kedJVvW3xglHPMamsXbWDMnG+5ePYy/548T7N2n+JR0IMtK5PHlfUa0R03T1fG90+euWHzyq180bkF/cf05vc12ynvW45PWzdhdO8J2jLLVfHGzdOVK+ev4ebpSrfBnTAzU7F63jqjnGN2iFm3AafRI4i/eJmEf8+Tr9knqD08eP7bNgDs/buhdnPj0YTk65bvs+Zo7t8n8VZyZwXLShWwa9OSZxu3pCo73ydNiD14COXJk5w7oSxmyNRXeUWuCGi//vorQUGpWzZfffUVPj4+LF68mNatWzNjxgwj1E6/jRu34eycn2+/7Y+npzvnz1+hefOOhIYmtz48Pd0pXPhVT7ybN2/TvHlHpkwZjb9/B8LC7jNo0Fhtl32AAgU8OH78L+3rQYP8GTTInwMHjtCwYascO7fs1KhyCR49j2Xh7mCinjynpKcTc7s0pICTPQCRT14Q9ihGmz9Bk8TMP44T8fg5VhZq3vFw4sfODanpXVib50V8Aj9sOUzE42dYWagp5p6f77+qQ6PKJXL8/LLD7q17cXRyoOvAjri4O3PjcgiD2n1D+N37ALi6u+BZ8NWA1bDb4QxqN5wB4/rweafmRN2PZsaoH7Vd9gEsrSzp+U1XChQpwIvnLzj891HG9fuBmCcxqY6fV8X+vZfHjg7Yd+mA2sWZhBs3eTBkOJrw5OumdnFB7fHqzoDKTIVDr+6ovTxBoyHx7j2ezF+sDYAvqQsXwqpyRaL7D8nR88lqhgyszitUSi54Mujh4cHUqVPp0KGDTvrKlSsZOnQo9+/f58KFC9SqVYuoKP3PqF5nbZ16eQLxZg/Xf23sKuQ5dXvp7wEn0re5WN6YQCE3KXB4b5aWV8Y948NaLkWceHOmXCBXtND69u2Lv78/QUFBvPfee6hUKo4fP86SJUv49ttvAdi5c6fOOAUhhBCZJ7ccs8l3331H8eLFmTt3LqtWrQKgdOnSLF68mDZt2gDg7+9Pr169jFlNIYQwGXmps0dG5YqABtC2bVvatm2b5vs2Nhnv1i2EECJ90kITQghhEqSFloWcnZ25cuUKrq6uODk5pdvV/sED/QNIhRBCZI5igr0cjRbQZs6cib29vfbnvLJsjBBCmAJTnCnEaAGtY8eO2p87depkrGoIIcRbKReM2MpyRn2GZmZm9saWmUqlemumhhJCiJxiigOrjRrQtmxJPaXMS4cPH+bHH380yW8RQghhbNLLMYvpW4770qVLjBgxgm3bttG2bVsmTJigZ08hhBD/hSn2cswVs+0D3Lt3j+7du1OxYkUSExMJDg5mxYoVFCki01gJIURWUxQlw1teYfSA9vjxY7755htKlizJ+fPn+fvvv9m2bRsVKpjIUvBCCJELJaFkeMsrjHrLccqUKUyePBlPT0/Wrl2r9xakEEKIrJeXWl4ZZdSANnz4cGxsbChZsiQrVqxgxYoVevNt3rw5h2smhBCmTTqFZLEOHTrIgGohhDACaaFlseXLlxvz8EII8dbKS8/GMkomJxZCiLeQtNCEEEKYBJkpRAghhEmQTiFCCCFMginecjT6wGohhBA5TzHgX2bMmzeP4sWLY21tjY+PDwcPHkw3//79+/Hx8cHa2poSJUqwYMECg48pAU0IId5C2Tn11fr16xkwYAAjR44kODiYmjVr0rhxY0JDQ/XmDwkJoUmTJtSsWZPg4GC+/fZb+vXrx6ZNmww6rkoxwXantbXM/5gZD9d/bewq5Dl1e+0wdhXypM3FZPypoQoc3pul5VlYFsxw3oT4uwaVXa1aNapWrcr8+fO1ad7e3jRv3pyAgIBU+b/55hu2bt3KxYsXtWn+/v6cOXOGI0eOZPi40kITQoi3kGLAFhcXx5MnT3S2uLg4veXGx8cTFBREw4YNddIbNmzI4cOH9e5z5MiRVPkbNWrEyZMnSUhIyPA5mWSnkNhY/c1aY4uLiyMgIIARI0ZgZWVl7OrkGbn5uh1tNszYVdArN1+z3Oxtum6JBrS6xo4dy7hx43TSxowZw9ixY1PljYqKQqPR4OHhoZPu4eFBeHi43vLDw8P15k9MTCQqKgovL68M1VNaaDkoLi6OcePGpfnNRugn181wcs0yR66bfiNGjODx48c624gRI9LdJ+W0hoqipDvVob78+tLTY5ItNCGEEFnHysoqwy1WV1dX1Gp1qtZYREREqlbYS56ennrzm5ub4+LikuF6SgtNCCFElrG0tMTHx4fAwECd9MDAQGrUqKF3Hz8/v1T5d+3aha+vLxYWFhk+tgQ0IYQQWWrQoEEsWbKEpUuXcvHiRQYOHEhoaCj+/v5A8i3MDh06aPP7+/tz69YtBg0axMWLF1m6dCk///wzQ4YMMei4cssxB1lZWTFmzBiTf9ic1eS6GU6uWebIdcsarVq1Ijo6mvHjxxMWFkb58uXZsWMHRYsWBSAsLExnTFrx4sXZsWMHAwcO5KeffqJAgQLMmTOHzz//3KDjmuQ4NCGEEG8fueUohBDCJEhAE0IIYRIkoAkhhDAJEtByqTp16jBgwADt6+fPn/P555/j4OCASqXi0aNHbyzj5s2bqFQqTp8+nW31NMTy5cvJnz9/unnGjh1L5cqV083TqVMnmjdvnmX1epsUK1aMWbNmZVl5KT+nuV1GPoMpyect73hrA1qnTp1QqVTazcXFhY8++oizZ8/maD327dunN0Bt3ryZCRMmaF+vWLGCgwcPcvjwYcLCwnB0dMzRer5JWr/0r59fq1atuHLlSs5XLhd5+bl72X35db1790alUtGpU6f/fJy0/nCfOHGCHj16/Ofyc6OX13bSpEk66b/99pt2tons+gxm9RcFkTlvbUAD+OijjwgLCyMsLIy///4bc3NzPvnkE2NXCwBnZ2fs7e21r69fv463tzfly5fH09PToOlgcgsbGxvc3d2NXQ2jK1y4MOvWrePFixfatNjYWNauXUuRItm7UoSbmxv58uXL1mMYk7W1NZMnT+bhw4d635fPoGl7qwOalZUVnp6eeHp6UrlyZb755htu375NZGQkAHfv3qVVq1Y4OTnh4uJCs2bNuHnzpnb/EydO0KBBA1xdXXF0dKR27dqcOnVK+76+W36PHj1CpVKxb98+bt68Sd26dQFwcnLS+Xb++q2cOnXqMH36dA4cOIBKpaJOnTpA8hxnv/32m8455c+fn+XLl2flZcoy+loNkyZNwsPDA3t7e7p27UpsbKzO+xqNhkGDBpE/f35cXFwYNmxYqvWZFEVhypQplChRAhsbGypVqsTGjRu1779sJf7999/4+vqSL18+atSoweXLl7PtXNNTtWpVihQpwubNm7VpmzdvpnDhwlSpUgWAlStX4uLikmpOwc8//1w7IPXMmTPUrVsXe3t7HBwc8PHx4eTJk+zbt4/OnTvz+PFj7R2Il5PIpmxJPHr0iB49euDh4YG1tTXly5dn+/btAERHR9O6dWsKFSpEvnz5qFChAmvXrs3GK/Pf1a9fH09PT71LlID+z+DEiRNxd3fH3t6ebt26MXz4cL23vadNm4aXlxcuLi706dNHOwt8nTp1uHXrFgMHDtReb2Ecb3VAe11MTAxr1qyhZMmSuLi48Pz5c+rWrYudnR0HDhzg0KFD2NnZ8dFHHxEfHw/A06dP6dixIwcPHuTo0aO8++67NGnShKdPn2bomIULF9YuYHf58mXCwsKYPXt2qnybN2+me/fu+Pn5ERYWpvOHMC/79ddfGTNmDN9//z0nT57Ey8uLefPm6eSZPn26dtaAQ4cO8eDBA7Zs2aKT57vvvmPZsmXMnz+f8+fPM3DgQNq1a8f+/ft18o0cOZLp06dz8uRJzM3N6dKlS7afY1o6d+7MsmXLtK+XLl2qU58vv/wSjUbD1q1btWlRUVFs376dzp07A9C2bVsKFSrEiRMnCAoKYvjw4VhYWFCjRg1mzZqFg4OD9g6EvhkXkpKSaNy4MYcPH2b16tVcuHCBSZMmoVargeRWo4+PD9u3b+fff/+lR48etG/fnmPHjmXXZfnP1Go1P/zwAz/++CN37tx5Y/41a9bw/fffM3nyZIKCgihSpIjOGl4v7d27l+vXr7N3715WrFjB8uXLtV8cN2/eTKFChbSDiMPCwrL6tERGKW+pjh07Kmq1WrG1tVVsbW0VQPHy8lKCgoIURVGUn3/+WSldurSSlJSk3ScuLk6xsbFRdu7cqbfMxMRExd7eXtm2bZuiKIoSEhKiAEpwcLA2z8OHDxVA2bt3r6IoirJ3714FUB4+fKhTVu3atZX+/ftrX/fv31+pXbu2Th5A2bJli06ao6OjsmzZsjSPn11SXs+Xm7W1tfb8li1bpjg6Omr38fPzU/z9/XXKqVatmlKpUiXtay8vL2XSpEna1wkJCUqhQoWUZs2aKYqiKDExMYq1tbVy+PBhnXK6du2qtG7dWlGUV9d49+7d2vf/+OMPBVBevHiRRVcgYzp27Kg0a9ZMiYyMVKysrJSQkBDl5s2birW1tRIZGak0a9ZM6dixo6IoitKrVy+lcePG2n1nzZqllChRQvuZtLe3V5YvX673OCmv9UtFixZVZs6cqSiKouzcuVMxMzNTLl++nOH6N2nSRBk8eLD2dcrPqTG9vLaKoijVq1dXunTpoiiKomzZskV5+acu5XWpVq2a0qdPH51yPvjgA53PYMeOHZWiRYsqiYmJ2rQvv/xSadWqlfb169dVGM9b3UKrW7cup0+f5vTp0xw7doyGDRvSuHFjbt26RVBQENeuXcPe3h47Ozvs7OxwdnYmNjaW69evA8mzQfv7+1OqVCkcHR1xdHQkJiYmzWXGTd3r1/PltmTJkjTzX7x4ET8/P520118/fvyYsLAwnTRzc3N8fX21ry9cuEBsbCwNGjTQ/j/Z2dmxcuVK7f/TSxUrVtT+/HJ9pYiIiMyd7H/k6urKxx9/zIoVK1i2bBkff/wxrq6uOnm6d+/Orl27uHs3ed2qZcuWaTs+QPJ8ed26daN+/fpMmjQp1fm+yenTpylUqBClSpXS+75Go+H777+nYsWKuLi4YGdnx65du/LE53vy5MmsWLGCCxcupJvv8uXLvP/++zppKV8DlCtXTttyheTPj7E+OyJtb/Vcjra2tpQsWVL72sfHB0dHRxYvXkxSUhI+Pj6sWbMm1X5ubm5Acq+qyMhIZs2aRdGiRbGyssLPz097S9LMLPn7gvLaMx9DVl99E5VKlep5UlaWb6iU1xPI0G2f/yIpKQmAP/74g4IFdZeUTzkf3+uzdr8MCi/3N4YuXbrw9ddfA/DTTz+ler9KlSpUqlSJlStX0qhRI86dO8e2bdu0748dO5Y2bdrwxx9/8OeffzJmzBjWrVtHixYtMnR8GxubdN+fPn06M2fOZNasWVSoUAFbW1sGDBig/XznZrVq1aJRo0Z8++23b+w1mtY6XK9LOeO7SqUy6mdH6PdWt9BSUqlUmJmZ8eLFC6pWrcrVq1dxd3enZMmSOtvLLvMHDx6kX79+NGnShHLlymFlZUVUVJS2vJeB7/V76inHhFlaWgLJ34YN5ebmplP21atXef78ucHlGIu3tzdHjx7VSXv9taOjI15eXjppiYmJBAUFaV+XLVsWKysrQkNDU/0/FS5cOPtP4j94+Tw2Pj6eRo0a6c3TrVs3li1bxtKlS6lfv36qcypVqhQDBw5k165dfPbZZ9rncpaWlm/8TFWsWJE7d+6k2Y394MGDNGvWjHbt2lGpUiVKlCjB1atXM3GmxhEQEMC2bds4fPhwmnlKly7N8ePHddJOnjxp8LEycr1F9nurA1pcXBzh4eGEh4dz8eJF+vbtS0xMDJ9++ilt27bF1dWVZs2acfDgQUJCQti/fz/9+/fXtjpKlizJqlWruHjxIseOHaNt27Y633ptbGyoXr06kyZN4sKFCxw4cIDvvvtOpw5FixZFpVKxfft2IiMjiYmJyXD9P/zwQ+bOncupU6c4efIk/v7+Bq0dZGz9+/dn6dKlLF26lCtXrjBmzBjOnz+fKs+kSZPYsmULly5donfv3jpj9uzt7RkyZAgDBw5kxYoVXL9+neDgYH766SdWrFiRw2dkGLVazcWLF7l48aLO7azXtW3blrt377J48WKdTiMvXrzg66+/Zt++fdy6dYt//vmHEydO4O3tDST3ZoyJieHvv/8mKipK7xed2rVrU6tWLT7//HMCAwMJCQnhzz//5K+//gKSP9+BgYEcPnyYixcv0rNnz1SLMOZmFStWpG3btvz4449p5unbty8///wzK1as4OrVq0ycOJGzZ88a3FOxWLFiHDhwgLt37+p8qRU5660OaH/99RdeXl54eXlRrVo1Tpw4wYYNG6hTpw758uXjwIEDFClShM8++wxvb2+6dOnCixcvcHBwAJJ7pj18+JAqVarQvn17+vXrl2qMy9KlS0lISMDX15f+/fszceJEnfcLFizIuHHjGD58OB4eHtpbUBkxffp0ChcuTK1atWjTpg1DhgzJU2OMWrVqxejRo/nmm2/w8fHh1q1b9OrVSyfP4MGD6dChA506dcLPzw97e/tUt9QmTJjA6NGjCQgIwNvbm0aNGrFt2zaKFy+ek6eTKQ4ODtrPU1rvf/7559jZ2ekMXFer1URHR9OhQwdKlSpFy5Ytady4MePGjQOgRo0a+Pv706pVK9zc3JgyZYre8jdt2sR7771H69atKVu2LMOGDdO2NEaNGkXVqlVp1KgRderUwdPTM8/NmDFhwgS9txBfatu2LSNGjGDIkCFUrVqVkJAQOnXqhLW1tUHHGT9+PDdv3uSdd97R3pkROU+WjxEil2vQoAHe3t7MmTPH2FV5KzRo0ABPT09WrVpl7KoIA73VnUKEyM0ePHjArl272LNnD3PnzjV2dUzS8+fPWbBgAY0aNUKtVrN27Vp2795NYGCgsasmMkECmhC5VNWqVXn48CGTJ0+mdOnSxq6OSVKpVOzYsYOJEycSFxdH6dKl2bRpE/Xr1zd21UQmyC1HIYQQJuGt7hQihBDCdEhAE0IIYRIkoAkhhDAJEtCEEEKYBAloQgghTIIENCEyaOzYsToLP3bq1MkoM2foWzhWCCEBTZiAl0uqqFQqLCwsKFGiBEOGDOHZs2fZetzZs2dneHVwCUJCZD8ZWC1MwkcffcSyZctISEjg4MGDdOvWjWfPnqVafTghISHLJnB+ueqCECJ3kBaaMAlWVlZ4enpSuHBh2rRpQ9u2bfntt9+0twmXLl1KiRIlsLKyQlEUHj9+TI8ePXB3d8fBwYEPP/yQM2fO6JQ5adIkPDw8sLe3p2vXrsTGxuq8n/KWY1JSEpMnT6ZkyZJYWVlRpEgRvv/+ewDtRMlVqlRBpVJRp04d7X7Lli3D29sba2trypQpw7x583SOc/z4capUqYK1tTW+vr4EBwdn4ZUTwnRIC02YJBsbG+1ip9euXePXX39l06ZN2mVaPv74Y5ydndmxYweOjo4sXLiQevXqceXKFZydnfn1118ZM2YMP/30EzVr1mTVqlXMmTOHEiVKpHnMESNGsHjxYmbOnMn//d//ERYWxqVLl4DkoPT++++ze/duypUrp10Hb/HixYwZM4a5c+dSpUoVgoOD6d69O7a2tnTs2JFnz57xySef8OGHH7J69WpCQkLo379/Nl89IfIoRYg8rmPHjkqzZs20r48dO6a4uLgoLVu2VMaMGaNYWFgoERER2vf//vtvxcHBQYmNjdUp55133lEWLlyoKIqi+Pn5Kf7+/jrvV6tWTalUqZLe4z558kSxsrJSFi9erLeOISEhCqAEBwfrpBcuXFj55ZdfdNImTJig+Pn5KYqiKAsXLlScnZ2VZ8+ead+fP3++3rKEeNvJLUdhErZv346dnR3W1tb4+flRq1Yt7cKORYsW1VmjKigoiJiYGFxcXLCzs9NuISEhXL9+HYCLFy/i5+enc4yUr1938eJF4uLiqFevXobrHBkZye3bt+natatOPSZOnKhTj0qVKumsc5dePYR4m8ktR2ES6taty/z587GwsKBAgQI6HT9sbW118iYlJeHl5cW+fftSlZM/f/5MHf/1lcozKikpCUi+7VitWjWd917eGlVk7nAhMkwCmjAJtra2lCxZMkN5q1atSnh4OObm5hQrVkxvHm9vb44ePUqHDh20aUePHk2zzHfffRcbGxv+/vtvunXrlur9l8/MXq4GDeDh4UHBggW5ceMGbdu21Vtu2bJlWbVqFS9evNAGzfTqIcTbTG45irdO/fr18fPzo3nz5uzcuZObN29y+PBhvvvuO06ePAlA//79Wbp0KUuXLuXKlSuMGTOG8+fPp1mmtbU133zzDcOGDWPlypVcv36do0eP8vPPPwPg7u6OjY0Nf/31F/fv3+fx48dA8mDtgIAAZs+ezZUrVzh37hzLli1jxowZALRp0wYzMzO6du3KhQsX2LFjB9OmTcvmKyRE3iQBTbx1Xi7qWKtWLbp06UKpUqX46quvuHnzJh4eHgC0atWK0aNH88033+Dj48OtW7fo1atXuuWOGjWKwYMHM3r0aLy9vWnVqhUREREAmJubM2fOHBYuXEiBAgVo1qwZAN26dWPJkiUsX76cChUqULt2bZYvX67t5m9nZ8e2bdu4cOECVapUYeTIkUyePDkbr44QeZcs8CmEEMIkSAtNCCGESZCAJoQQwiRIQBNCCGESJKAJIYQwCRLQhBBCmAQJaEIIIUyCBDQhhBAmQQKaEEIIkyABTQghhEmQgCaEEMIkSEATQghhEv4fVcLbIKI2L9AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('loading model with best weights')\n",
    "model.load_weights('isthemountainout.best.h5')\n",
    "\n",
    "validations = dataset.validation\n",
    "predictions = tf.math.argmax(\n",
    "  tf.nn.softmax(\n",
    "    model.predict(validations)), axis=1)\n",
    "labels = tf.argmax(tf.concat([label for _, label in iter(validations)], axis=0), axis=1)\n",
    "cm = confusion_matrix(labels, predictions, labels=list(range(len(dataset.validation.class_names))))\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "sns.heatmap(\n",
    "  cmn,\n",
    "  annot=True,\n",
    "  fmt='.2f',\n",
    "  xticklabels=dataset.validation.class_names,\n",
    "  yticklabels=dataset.validation.class_names)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mountain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "675b856ca8a14374dc4009cf40e9ead9d95917e285fd3b96229cb66bb660ef16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
